% Change 'digital' to 'printed' before printing
\documentclass[
  digital, %% This option enables the~default options for the
           %% digital version of a~document. Replace with `printed`
           %% to enable the~default options for the~printed version
           %% of a~document.
  table,   %% Causes the~coloring of tables. Replace with `notable`
           %% to restore plain tables.
  lof,     %% Prints the~List of Figures. Replace with `nolof` to
           %% hide the~List of Figures.
  lot,     %% Prints the~List of Tables. Replace with `nolot` to
           %% hide the~List of Tables.
  oneside,
  %% More options are listed in the~user guide at
  %% <http://mirrors.ctan.org/macros/latex/contrib/fithesis/guide/mu/fi.pdf>.
]{fithesis3}
%% The~following section sets up the~locales used in the~thesis.
\usepackage[resetfonts]{cmap} %% We need to load the~T2A font encoding
\usepackage[main=english, slovak]{babel}

%% For non-Latin scripts, it may be necessary to load additional 
%% fonts:
\usepackage{paratype}
%%1
%% The~following section sets up the~metadata of the~thesis.
\thesissetup{
    date          = 2017/5/22,
    university    = mu,
    faculty       = fi,
    type          = mgr,
    author        = Zuzana Dankovčíková,
    gender        = f,
    advisor       = {Bruno Rossi, Ph.D.},
    title         = {Custom Roslyn Tool for Static Code Analysis},
    TeXtitle      = {Custom Roslyn Tool for Static Code Analysis},
    keywords      = {static code analysis, software quality, Roslyn, .NET compiler platform, C\#, compilers, code review, Kentico, analyzer, code fix, ...},
    TeXkeywords   = {static code analysis, software quality, Roslyn, .NET compiler platform, C\#, compilers, code review, Kentico, analyzer, code fix, \ldots},
}
\thesislong{abstract}{
    TODO: This is the~abstract ...
}
\thesislong{thanks}{
I wish to~thank my advisor Dr.~Bruno Rossi for his~constant feedback and~valuable advice during the~work on~this thesis. I~would also like to~thank my~consultants Vít Svoboda and Petr Svirák, who never hesitated to~explain the~dark corners of~the~Kentico CMS solution. Furthermore, to~Vít Svoboda for his~incredible diligence and patience when deploying the~analyzers. Finally, I~want to thank my~parents and my~boyfriend Pavol for~their love, support and patience not~only in~the~last year but~also throughout the~whole course of~my~studies.
}

%% The~following section sets up the~bibliography.
\usepackage{csquotes}
\usepackage[              %% When typesetting the~bibliography, the
  backend=biber,          %% `numeric` style will be used for the
  style=numeric,          %% entries and the~`numeric-comp` style
  citestyle=numeric-comp, %% for the~references to the~entries. The
  sorting=none,           %% entries will be sorted in cite order.
  sortlocale=auto         %% For more unformation about the~available
]{biblatex}               %% `style`s and `citestyles`, see:
%% <http://mirrors.ctan.org/macros/latex/contrib/biblatex/doc/biblatex.pdf>.
\addbibresource{mybib.bib} %% The~bibliograpic database within
                          %% the~file `example.bib` will be used.

\usepackage{makeidx}      %% The~`makeidx` package contains
\makeindex                %% helper commands for index typesetting.

%% These additional packages are used within the~document:
\usepackage{multirow}
\usepackage{paralist}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{url}
\usepackage{menukeys}
\usepackage{tikz-qtree}
\usepackage{minted}
\usemintedstyle{vs}

\begin{document}
% =================================================================
% ============================= CHAPTER 1 =========================
% ====================================================  =============
\chapter{Introduction}
%First some paragraphs for the~introduction of the~topic (references to general articles can be taken from other parts of the~thesis). In this case, this can be an~introduction about the~importance of static code analysis in general (and in the~specific for Kentico);

Software bugs have been around for as long as the~software itself. Even for a~program that has been thoroughly tested, the~bugs are inevitable. The~longer they are present in the~code, the~more expensive and difficult it is for them to be removed. 

Every year, billions of dollars are lost due to software that does not perform as expected. 
%Hours of downtime, maintenance costs, countless calls to customer support, and angry users among the~visible implications of the~software product not meeting its requirements. 
While the~conformance to the~customer requirements is mostly validated by functional testing, there is more to software quality than that. To cover the~attributes like maintenance, readability, reusability or testability, that directly affect customers' perception of product's quality, other inspection techniques need to be involved as well. Different possibilities from formal inspections of the~code, peer code reviews, pair programming, to use of automated tools for static code analysis, can be applied to ensure the~quality of the~code. The~key to achieving quality software lies in the~combination of these techniques. 

With the~ever-growing sizes of the~software products, arose the~need for automated tools that would help with identifying code issues. Applying static code analysis on a~software project brings a~first form of code review before the~software is even run. They can be applied in the~earliest stages of the~software development lifecycle. Unlike testing, static code analysis can be done on unfinished or even uncompilable source code. Moreover, it identifies the~root causes of the~bugs, unlike dynamic testing which only points out to their consequences. 

Use of static code analysis tools provides an~obvious solution for they are great in unveiling bugs that are commonly missed by unit, integration or system testing. Furthermore, they are cheaper, repeatable, and more efficient than manual code reviews. 

For a~software company like Kentico, that develops a~product for thousands of other developers and marketers building their own business on the~top of Kentico's CMS, high source code quality is extremely important. It means faster time-to-market, less maintenance effort, fewer bugs, and therefore reduced costs for customer support. It enables engineers to focus on developing new features rather then dealing with unmaintainable code base. 

%then there should be some Problem Statement section: which problem the~current thesis addresses. It should also tell why it's an~important problem to be solved;

Over the~course of last ten years, many internal guidelines and best practices were established at Kentico. Since it became increasingly harder to keep a~track of all those rules during the~manual code reviews, a~console application BugHunter was developed. It checked for the~most common mistakes and violations of internal rules within the~Kentico solution. The~checks were performed by simple string matching. Even though its simplicity shrank the~initial costs of developing such tool to minimum, the~reliability paid the~price. 

Occasional false positive results meant that some pieces of the~code had to be written in an~obscure way in order to pass the~BugHunter check. Due to lack of any semantic analysis, many issues were not detected at all, and with false negatives slipping also through the~code reviews, this could have caused bugs in production. 

%+ the~goal(s) of the~thesis that needs to be reached
%+ the~contribution that the~the thesis provides to a~reader (e.g. also a~prototype software is a~contribution)\
The~goal of this thesis is to create a~new static code analysis tool, that would replace the~original C\# checks in BugHunter, and would mitigate the~flaws of the~previous solution. The~tool should be written using the~new .NET Compiler Platform (code-named \textit{"Roslyn"}) and should be integrated to both Visual Studio and the~continuous integration process at Kentico. The~new BugHunter analyzers should raise warnings for code that does not comply to Kentico's internal guidelines. Where suitable, the~tool should also provide an~instant code fix. Since the~tool will be deployed in the~production, it needs to be thoroughly tested and be efficient, so that it does not degrade the~developers' experience.

The~implemented analyzers are not be concerned with naming or ordering conventions, since there are already many (also Roslyn-based) tools dealing with this problem. These can be easily configured to specific needs of the~development team. Instead, the~new analyzers will only focus on the~rules which require tailored approach that cannot be found in other available solutions. 

%+ the~structure for all the~chapters in the~thesis
Discussing the~thesis structure, the~second chapter provides a~theoretical background behind the~static code analysis tools in general -- source code compilation. It shortly describes the~phases of the~compilation process and focuses on the~analysis, or \textit{front end} part, which is fundamental for any static code analysis tool.

In the~third chapter, the~concept of the~static code analysis is described. It informs the~reader about the~possibilities of analyzing the~compiled code and then focuses on the~analysis of the~source code. It provides an~overview of the~problems that can be solved by static code analysis, and lists the~advantages and disadvantages. The~last section presents the~tools for static code analysis available for .NET platform.

The~fourth chapter of the~thesis concludes the~theoretical part by introducing the~.NET Compiler Platform which was utilized during the~development. It gives an~insight into the~internals of the~CSharp compiler, familiarizes the~reader with the~immutable data structures used when working with Roslyn, and demonstrates how the~Diagnostic APIs (Application Programming Interfaces) can be applied to build custom static code analyzers and code fixes.

The~second part of the~thesis is concerned with the~implementation of the~new BugHunter analyzers. In the~fifth chapter the~original BugHunter application is introduced, along with its~issues, that are being addressed by this thesis. It defines the~analyzers' categories and shows some of the~design patterns that were utilized during the~development. The~chapter shortly mentions the~implemented code fixes and discusses the~importance of tests.

Lastly, the~sixth chapter focuses on the~performance aspect of the~developed tool. It explains how the~performance of the~separate analyzers was measured and specifically points out the~iterative optimization of one particular analyzer. It also assesses the~impact of the~analyzers on build times and summarizes the~views of the~development team on the~new tool.

% =================================================================
% ============================= CHAPTER 2 =========================
% =================================================================
\chapter{Compiling Source Code}
\label{chap:compilers}
This chapter explains the~theory behind the~source code compilation. It focuses primarily on~an~analysis part of~a~compilation process which is fundamental for the~rest of~the~thesis for~being a~concept behind all~static code analysis tools.

As~per~\cite{dragon-book}, a~compiler is a~program that can read a~program in a~\textit{source} language and~translate it into a~semantically equivalent program in~a~\textit{target} language while reporting any errors detected during the~translation. The~compiler may sometimes rely on~other programs. For example, \textit{preprocessor} is responsible for~collecting the~source code to~be~fed to~the~compiler by expanding shorthands (macros) into~source language statements. 

The~compilation process can be divided into~two parts: \textit{analysis} and \textit{synthesis}; commonly referred~to as~\textit{front end} and \textit{back end} of~the~compiler.

The~purpose of~the~analysis part is~to break~up the~source program into~chunks and build~up a~grammatical structure that it corresponds~to, based on~the~source language grammar. This structure is subsequently transformed into an~intermediate representation of the~source program. Along the~way, the~compiler collects information about the~program and stores it into a~data structure called \textit{symbol table}. If~any~errors in~syntax or semantics are encountered, analysis part shall inform the~programmer about the~problem. Otherwise, both intermediate representation and symbol table are passed to~the~synthesis part where they are used for~the~construction of~the~target program.

The~two main steps of compilation process internally consist of different phases as shown in Figure~\ref{fig:compiler-phases}. Each phase transforms one representation of source language into another, and passes it to the~following phase while working with the~symbol table during the~process. In synthesis phase, an~optional machine-independent optimizations can take place and are done on the~top of~the~intermediate representation. After the~target machine code is generated, additional machine-dependent code optimizations are performed.

\begin{figure}[h!]
		\centering
			\includegraphics[scale=0.80]{img/compiler-phases}
		\caption{The~compiler~phases, adopted from~\cite{dragon-book}}
		\label{fig:compiler-phases}
\end{figure}

For the~purpose of this thesis, mainly the~analysis part is relevant and following section will elaborate on its respective phases.

  \section{Lexical analysis}
The~compilation process starts with \textit{lexical analysis} or \textit{scanning}. The~scanner transforms a~stream of characters of the~source program, as written by the~programmer, into a~series of meaningful sequences called \textit{lexemes}. Most programming languages allow for an~arbitrary number of white spaces to be present in the~source text to aid readability. However, white spaces, similarly as comments, are unimportant for the~target code generation itself, and thus the~lexical analyzer is responsible for discarding them completely.

In order to be able to correctly recognize the~lexeme, lexical analyzer may need to read ahead. For example, in C--like languages if the~scanner sees \textit{<} character, it cannot decide whether it is a~lexeme for \textit{"less than"} operator or it is s part of \textit{"less then or equal to"} lexeme. In order to do that, it needs to read ahead and see if the~following character is \textit{=} or not. Reading ahead is usually implemented with an~input buffer which the~lexical analyzer can read from and push back to. As pointed out in~\cite{dragon-book}, the~use of buffer also boosts the~performance since fetching block of characters is more efficient than fetching one at a~time.

The~lexical analyzer typically uses regular expressions to identify the~lexemes and for each lexeme, it outputs a~\textit{token} (or~\textit{token object}) of~the~form 
\begin{equation}
  \langle token \textnormal{-} name, attribute \textnormal{-} name \rangle \textnormal{.}
\end{equation}

\noindent
For an~input sequence 
\begin{equation}
  total = 42 + base * interest
\end{equation}
 
the scanner output could be
\begin{equation}
  \langle id, 0 \rangle 
  \langle = \rangle 
  \langle num, 1 \rangle 
  \langle + \rangle 
  \langle id, 2 \rangle 
  \langle * \rangle 
  \langle id, 3 \rangle
\end{equation}

Lexemes can be divided into logical groups such as identifiers, relational operators, arithmetical operators, constants or keywords as seen in the~example above. The~scanner often uses regular expressions to identify tokens.

Each identifier (\textit{id}) has an~attribute which points to the~entry of the~symbol table, where information about identifier name, type or position in the~source text is stored. Similar holds for constants like \textit{42} in the~example. In the~(2.3) example, the~assignment and addition symbols do not have attributes, but different representation can be used, such as $ \langle bin \textnormal{-} op, 2 \rangle $. In this case, \textit{bin-op} would denote it is a~binary operator. A~number two would be a~pointer to~the~symbol table with all~the~symbols for binary operations, while the~second index suggests that it represents an~addition.

  \section{Syntax Analysis}
The~stream of token objects along with partially populated symbol table is an~input for the~subsequent compiler phase -- \textit{syntax analysis}, or \textit{parsing}. The~parser has to verify that the~sequence of token names can be produced by the~source language grammar. For a~well-formed program, it shall output a~\textit{syntax tree}, often referred to as an~abstract syntax tree (AST)\footnote{The~AST is an~intermediate representation of~the~source program in which each interior node represents an~operation (programming construct) with the~children of the~node representing the~arguments of that operation. As opposed to \textit{parse syntax tree}, in which interior nodes are nonterminals of the~grammar, ASTs are more lightweight and they might omit some nodes which exist purely as a~result of grammar's production rules~\cite{secure-programming-with-sca}.}.

The~resulting AST for the~token stream generated in (2.2) is depicted in Figure~\ref{fig:compilers-abstract-syntax-tree}. The~tree shows how multiplication precedence rule of the~ grammar has been applied on~the~expression.

\begin{figure}
  \centering
  \begin{tikzpicture}
  \tikzset{every tree node/.style={align=center,anchor=north}}
  \Tree[.{$\langle = \rangle$} 
        [.{$\langle id, 0 \rangle$} ]
        [.{$\langle + \rangle$} 
          [.{$\langle num, 1 \rangle $} ]
          [.{$\langle * \rangle $} 
            [.{$\langle id, 2 \rangle $} ]
            [.{$\langle id, 3 \rangle $} ]
          ]
        ]
      ]
  \end{tikzpicture}
  \caption{Abstract Syntax Tree}
  \label{fig:compilers-abstract-syntax-tree}
\end{figure}

The~syntax analyzer uses a~context free grammar (CFG) to form the~syntax tree. The~CFG is defined by a~4-tuple consisting of:
\begin{description}
  \item[Terminals] -- token names (first component of the~token) as obtained from the~previous compilation step.
  \item[Nonterminals] -- syntactic variables that help to impose the~hierarchical structure of the~language and represent set of strings.
  \item[Start symbol] -- a~special nonterminal which set of strings represents the~language generated by the~grammar.
  \item[Productions] -- rules that specify how nonterminals can be rewritten to sequences of zero or more terminal and nonterminal symbols. 
\end{description}

An~example of a~production denoting the~construction of a~\textit{while-cycle} would be
\begin{equation}
  stmt 
  \rightarrow 
  \textbf{while}\ 
  \textbf{(}\ expr\ \textbf{)}\ 
  \textbf{\{}\ stmt\ \textbf{\}} 
  \textnormal{,}
\end{equation}
\noindent
where nonterminals \textit{stmt} and \textit{expr} stand for a~statement and expression respectively (defined further by other productions). Symbols in bold represent terminals of the~grammar (open and close parenthesis, and curly braces, \textit{while} keyword).

\subsection{Error Handling}
There are several types of errors that can be encountered during the~compilation process:
\begin{compactitem}
  \item\textbf{lexical errors}, such as misspelling the~identifier name,
  \item\textbf{syntactic errors}, for example a~missing semicolon,
  \item\textbf{semantic error}, like incorrect number of function arguments,
  \item\textbf{logical errors}, that do not really prevent the~program from compiling, but can indicate possible mistakes (for instance using the~assignment operator \textit{=} instead of the~comparison operator \textit{==} in condition of an~\textit{if-statement}).
\end{compactitem} 

It is parser responsibility to report the~presence of potential syntactic error and recover from the~error in order to continue with syntactic analysis and be able to detect any subsequent errors. In~\cite{dragon-book}, two main strategies for the~error recovery are presented: \textit{panic-mode} and \textit{phrase-level} recovery.

\subsubsection{\textbf{Panic-Mode Recovery}}
In this method, after the~parser encounters an~error, it searches for a~\textit{synchronizing token} (usually delimiters such as semicolon or close brace) and, until found, all the~symbols are thrown away one by one. Even though panic-mode recovery often discards significant amount of input while searching for the~synchronization token, it is guaranteed not to end up in an~infinite loop.

\subsubsection{\textbf{Phrase-Level Recovery}}
Another approach the~parser can take to recover from an~erroneous input is to try to perform a~local correction. This can be achieved by replacing the~prefix of the~following input by some tokens that would enable syntactic analyzer to continue parsing. A prime example of phrase-level recovery is inserting a~missing semicolon or replacing comma with a~semicolon. Even though this technique is very powerful, as it can cope with all possible problems in the~input, it might lead to infinite loops (e.g. always inserting symbols ahead of the~current symbol).

\section{Semantic Analysis}
Although the~syntax analysis is able to check the~conformance of the~program to the~grammar of the~source language, it is not an~ultimate tool. Some language rules cannot be implied by CFG and an~additional step is needed to ensure semantic consistency. To do this, the~semantic analyzer uses the~AST and the~information from symbol tables collected in previous phases. While working, it can also add more details about symbols or even modify the~AST. 

A vital part of semantic analysis for any statically typed language\footnote{In statically typed language, type errors are reported by compiler during translation process, whereas in dynamically typed languages conversions between incompatible types are only discovered during runtime and can cause program failure.} is \textit{type checking}. Semantic analyzer has to ensure, that each operator is applied to matching operands. For example, a~multiplication operator can be called with either a~pair of integers or a~pair of floating-point numbers, that also implies the~result of the~operation. If the~semantic analyzer encounters an~expression where multiplication is used with numbers of different types, it must perform a~type conversion called \textit{coercion}. To coerce the~integer into floating-point representation, it may be necessary to alter the~AST and insert an~additional node to explicitly state that integer should be treated as floating-point~\cite{dragon-book}. 

Semantic analyzer utilizes the~information from symbol table to perform all sorts of other checks, to prevent semantic errors such as:
\begin{compactitem}
  \item \textbf{wrong arguments} -- number and types of arguments applied to a~function call,
  \item \textbf{multiple declaration} -- variable with the~same name declared more than once per~scope,
  \item \textbf{undeclared variable} -- usage of a~variable before its declaration.
\end{compactitem}
    
\section{Intermediate Code Generation}
The~semantic analysis is followed by an~\textit{intermediate code generation} which completes the~front end part of the~compilation process. Depending on the~specific compiler implementation, the~\textit{intermediate representation} (\textit{IR}) that is the~result of this phase can take different forms. The~IR should be easy to produce and easy to translate into the~target machine code. For some compilers, the~IR may be the~abstract syntax tree itself.

Together with symbol table, IR is passed to~the~back end part of the~compiler -- synthesis, where machine independent optimizations can be performed. These contain \textit{control flow analysis} where control flow graph is constructed and utilized in the~subsequent \textit{data flow analysis}. As a~result of these optimizations, compiler might remove dead code from the~IR or perform other optimizations that will lead to shorter and more efficient target code.

\bigskip
The~following chapters on static code analysis and .NET compiler platform will build upon the~fundamentals presented here and show how these concepts are relevant when considering the~implementation of a~static code analyzer.

% =================================================================
% ============================= CHAPTER 3 =========================
% =================================================================
\chapter{Static Code Analysis}
\label{chap:static-code-analysis}
This chapter introduces the~concept of static code analysis. It compares the~analysis of source and compiled code, and focuses on the~source code analysis, listing its advantages and disadvantages. The~end of the~chapter provides an~overview of static code analysis tools available for the~.NET Compiler Platform.

As per~\cite{sca-ppt} and~\cite{sca-approach-in-sw-dev}, static code analysis refers to a~process of assessing the~program based on its form, structure, content and documentation; and reasoning over its possible behaviours without actually executing the~code. The~aim of static code analysis is to check the~compliance to specific rules and identify parts of the~program that might lead to possible vulnerabilities. The~term static code analysis is mostly used when speaking of an~automated tool. In contrast, \textit{code inspections} or \textit{code reviews} are performed by humans and can benefit from using static code analysis tools.

\section{Source Code vs. Compiled Code Analysis}
There are two different approaches when analyzing a~program by an~automated tool~\cite{secure-programming-with-sca}: analyzing the~source code (as seen by the~compiler), or analyzing the~compiled code -- either some form of byte code~\footnote{An~intermediate representation of a~program, also known as "portable code", which is often an~input for just-in-time compilation by interpreters.} or an~executable.

Sometimes it might be very complicated, or even infeasible, to obtain the~actual source code of the~program to be analyzed and the~only possibility is to analyze the~executable code. When the~tool is looking at a~compiled version of the~program, the~ambiguity of how the~source code will be translated by~the~compiler is removed.

However, analyzing compiled code can be very complex. Even if the~tool manages to decode the~binary, it lacks the~original type information. Moreover, the~optimizations performed by the~compiler obscure the~original meaning of the~program and making sense of semantics out of implementation may be unattainable. Likewise, if the~error is found, reporting it to the~programmer can be challenging since there is not always a~clear mapping from binary back to source. 

Although the~above-mentioned complications speak clearly against analyzing binaries, the~situation is different when analyzing byte code formats (such as Java bytecode), where the~type and debugging information is present. The~rest of the~thesis focuses solely on source code analysis and the~following sections discuss the~theory behind it.

\section{How It Works}
There are many tools for static code analysis and each can be concerned with different attributes of the~program. However, for a~majority of them, the~basic structure looks the~same, as depicted in Figure~\ref{fig:static-code-analysis-internals}.

\begin{figure}[h!]
		\centering
			\includegraphics[scale=0.80]{img/static-code-analysis-internals}
		\caption{The~process of static analysis, adopted from~\cite{secure-programming-with-sca}}.
		\label{fig:static-code-analysis-internals}
\end{figure}


\subsection{Build a~Model}
In order to analyze the~program, the~analysis tool must first understand it. Therefore, the~initial task is to \textit{create a~structured model} that represents the~source code. This model has a~lot in common with the~AST and symbol tables that were discussed in Chapter~\ref{chap:compilers}. In fact, model building phase of static code analyzers closely mimics the~front end part of the~compilation process, executing lexical analysis, parsing and semantic analysis.

\subsection{Perform the~Analysis}
After obtaining the~model, the~next step is to perform the~actual analysis. Many different algorithms can be applied in this step and it is common that they are combined into one solution. The~approaches are often derived from techniques used by the~compilers, specifically:

\subsubsection{\textbf{Control Flow}}
In order to explore different execution paths that can take place when the~program is executed, the~static code analysis tool can construct a~\textit{control flow graph} on the~top of the~AST. The~nodes of the~graph represent basic blocks -- sequences of program instructions that will be all executed once block is entered. The~edges between basic blocks represent different paths that the~program can take depending on matched conditions. Any back edges in the~graph signal potential loops in the~program execution.

\subsubsection{\textbf{Tracking Data Flow}}
Data flow analysis is used to examine how data passes through the~program. Compilers utilize data flow analysis when doing code optimizations in order to remove unreachable code and allocate registers. An~example of how data flow analysis can be used by static analysis tools is to check that memory is always freed only once -- function \texttt{free(p)} was called at most once with the~address stored in pointer \texttt{p}.

\subsubsection{\textbf{Taint Analysis}}
According to~\cite{oswap-sca}, taint analysis attempts to identify variables containing possibly tainted user input using the~data flow analysis technique. If these variables are used as arguments to vulnerable functions without being sanitized first, the~tool reports their usage as vulnerable. The~taint propagation analysis is particularly relevant for security analysis, a~prime example being the~detection of a~potential SQL injection.

\subsection{Rules}
As stated in~\cite{sca-for-security}: \textit{"...if a~rule hasn’t been written yet to find a~particular problem, the~tool will never find that problem."} This implies that the~rules that specify what the~static analysis tool should report are just as important (or even more important) as the~heuristics and algorithms implemented by the~tool. Best tools for static code analysis externalize the~rule set in order to easily add, remove or alter the~rules, without modifying the~tool itself.

\subsection{Report the~Results}
An~often overlooked part of the~static analysis is the~result reporting. The~\cite{coverity-sca} asserts, that if a~programmer cannot understand the~output of the~static analysis, the~results are effectively useless since a~misunderstood explanation ends up with error being ignored or, worse, interpreted as a~false positive.

As discussed in~\cite{secure-programming-with-sca}, a~good static analysis tool should provide means of \textit{grouping and sorting} the~results, \textit{suppressing the~unwanted results} (either directly in the~code with pragmas or code annotations, or alternatively in a~configuration file) and mainly \textit{explaining the~results}. Every issue that is detected by the~tool should provide a~short title followed by a~detailed description of the~problem, severity of the~issue, recommendations on how the~problem can be fixed and possible further references to the~topic. The~tool can additionally provide a~confidence level estimating the~likelihood that the~finding is really correct.

\section{What Problems Can Be Solved by SCA}
There are different types of problems the~static analysis tool can tackle. This section enumerates some of the~categories applicable to static code analysis, as listed in~\cite{secure-programming-with-sca}.

\subsubsection{\textbf{Type Checking}}
The~integral part of every compiler for statically typed language. Rules are typically implied by the~language itself.

\subsubsection{\textbf{Style Checking}}
The~style checker defines rules for spacing, naming, commenting and general program structure that affect mostly the~readability and the~maintainability of the~program. 

\subsubsection{\textbf{Program Understanding}}
These tools aim to provide a~high-level program understanding beneficial mainly for larger codebases. They are most effective when integrated into the~IDEs\footnote{Integrated Development Environments} where they can support \textit{go to declaration} or \textit{find all references} features, or even automatic program refactorings such as renaming or extracting a~variable.

\subsubsection{\textbf{Bug Finding}}
The~ purpose of these type of static analyzers is to point out common mistakes in the~code. They report warnings in parts of the~program that are compliant with the~language specification but might not express the~programmer's intent, such as ignoring the~return value of a~function call.

Special type of bug finding checker is \textit{security review}, where specific vulnerabilities found in the~source code are reported. Security review searches for possible exploitations like buffer overflow or tainted inputs.
  
\section{Advantages}
One of the~key factors that advocate the~use of tools for static analysis, is how early in the~development process they can be applied. As opposed to dynamic testing, static code analysis can be performed on unfinished or even uncompilable code. The~longer the~defect stays in the~system, the~more damage it can cause and the~higher are the~costs of fixing it. As stated in~\cite[p. 29]{code-complete}, the~costs of fixing a~defect introduced during construction of a~program are 10-times higher if detected during system testing and 10 to 25-times higher in production, than it would be to fix it while still in development. Therefore, it is desirable to detect bugs as early as possible, which is where static code analysis can be leveraged.

Static inspections detect symptoms together with causes, whereas testing only points out the~symptoms with further effort required to find the~source of the~problem before it can be fixed~\cite[p. 472]{code-complete}.

Manual code inspections can be very time-consuming and require high level of expertise from the~reviewer. Static code analysis helps to make the~code review process more efficient by checking for well-known issues which do not have to be considered during the~code review.

Another advantage of automated code analysis is repeatability and scalability. Code analysis tool can be part of continuous integration\footnote{Process in which developers contribute regularly (multiple times a~day) into a~shared repository where the~code is continuously being verified by an~automated build and suite of automated tests.} (CI) process and can be also integrated to programming IDEs.

As such, they are great for programmers who get instant feedback and learn more about mistakes they made. The~tools enforce higher code quality and guidelines compliance. As a~result, the~code should be more consistent, maintainable and easier to debug.
  
\section{Disadvantages}
The~Rice's theorem~\cite{direct-proofs-of-rices-theorem} says, that any non-trivial question about program's semantics is undecidable. As a~consequence, there will never be a~static analysis tool able to answer all the~questions perfectly. The~tools can produce \textit{false positives} (a problem which does not actually exist is reported) and \textit{false negatives} (the program contains a~problem, but it was not reported by the~tool).

Prevailing complaints against static analysis tools concern false positives. A long list of false positives means real bugs can be overlooked and programmers can eventually lose trust in the~tool.

Worse, from the~security perspective, though, are the~false negatives. Not only the~bug was not found and might cause future problems, but they also provide a~false sense of security to the~programmers. 

As presented earlier in this chapter, a~vast majority of code inspection tools must build a~model of the~source program in order to be able to analyze it. This requires duplication of compiler's logic, which itself is fairly complicated, and there is no guarantee that the~tool interprets the~source exactly the~same as the~compiler does. Moreover, for the~authors of the~tool, it means the~parsing logic has to be always up to date with the~language version in use. 

\section{Static Code Analysis Tools Available for~.NET}
Even if imperfect, static analysis tools are still a~valuable asset in software development process. This section presents tools for static code analysis that are commonly used on the~.NET platform.

\subsection{FxCop}
FxCop is a~free tool by Microsoft for analyzing managed code assemblies (targeting .NET Framework) for conformance to .NET Framework Design Guidelines\footnote{\url{https://msdn.microsoft.com/en-us/library/ms229042(v=vs.110).aspx}} in areas such as design, localization, performance, security, naming or portability. 

It includes more than 200 predefined checks and a~possibility to add custom rules using FxCop SDK\footnote{Software Development Kit}. It is available in two forms: fully featured application with graphical user interface and a~command line tool that is easily integrated into an~automated build process. 

\subsection{StyleCop}
Another tool by Microsoft is an~open source project StyleCop\footnote{\url{https://github.com/StyleCop/StyleCop}} for analyzing C\# code for conformance to style and consistency with .NET Framework Design Guidelines. Unlike FxCop, StyleCop analysis is performed on the~source code, which enables it to look for a~different set of style violations. The~rules are divided into categories such as documentation, naming, ordering, spacing and readability. 

Some of the~rules are: placing the~opening curly brace on a~new line, spaces around binary operators, method names starting with an~upper-case. The~tool is configurable and development team can specify its own style to be checked, for example, to enforce spaces over tabs. It is available either as a~Visual Studio extension or as a~NuGet package that can be installed to the~project.

\subsection{CodeRush Classic}
CodeRush Classic\footnote{\url{https://www.devexpress.com/Products/CodeRush}} is a~solution-wide static code analysis tool for Visual Studio by vendor DevExpress. It enhances the~IDE with more advanced features like assembly decompilation, automated code generation, advanced code selection, code formatting and cleanup. The~tool focuses on developer's productivity by not only finding bugs but also providing an~automated way of fixing them.

It provides an~API enabling developers to extend the~basic functionality with 3rd party plugins such as spell checker or copy project. The~CodeRush Classic provides static analysis not only for .NET languages, but also for JavaScript, HTML and XML.

\subsection{Resharper}
Very similar to CodeRush, ReSharper is a~Visual Studio extension for .NET developers by Jet Brains\footnote{\url{https://www.jetbrains.com/resharper}}. It analyzes code quality of C\#, Visual Basic, ASP.NET, JavaScrtipt, TypeScript, CSS, HTML and XML. For each of these languages it is possible to define code style and formatting to make the~tool compatible with the~coding standards followed by a~development team. 

ReSharper provides hundreds of quick-fixes that solve discovered problems and has support for automated solution-wide refactorings. On the~top of static analysis there are additional plugins for performance (dotTrace) and memory (dotMemory) profiling, test runner and code coverage tool (dotCover) or .NET decompiler and assembly browser (dotPeek).


\subsection{Analyzers Written with Roslyn}
The~tools described above have one aspect in common -- they all need to parse the~code before they can analyze it. The~cost of maintaining a~custom C\# parser and keeping it up to date with every new language version is fairly difficult, inefficient, and of course, costly. 

With the~release of new .NET Compiler Platform (Roslyn), which is discussed in detail in the~following chapter, the~need for parsing C\# and Visual Basic sources is eliminated and tools that build upon this platform can concentrate solely on the~analysis itself.

Some vendors, like Jet Brains, who invested years of development into the~creation of the~tools, claim~\cite{resharper-and-roslyn-qa}, it does not pay off to rewrite the~whole program so that it uses new Microsoft compiler. Not only would it take an~enormous effort to rewrite all the~functionality to use the~new framework, but they would also risk destabilizing the~product and losing years of optimizations and testing. Moreover, ReSharper is multilingual tool whereas .NET Compiler platform "only" provides C\# and Visual Basic parsers.

Other companies, such as DevExpress with CodeRush\footnote{CodeRush Classic referrs to the~version before Roslyn} or Microsoft with StyleCop Analyzers, decided to use this new approach. The~effects on Visual Studio performance were immediate. Neither the~solution has to be parsed by the~tool, nor duplicate syntax trees need to be stored. As a~result, the~load times and memory consumption were significantly lowered.

The~Roslyn APIs also gave rise to more open source projects dealing with static code analysis, such as CodeCracker\footnote{\url{https://code-cracker.github.io}}. As challenging as it was in the~past, static code analysis is now rather easy, thanks to powerful analysis APIs. The~following chapter takes a~look at the~.NET Compiler Platform and how it can be used to write custom tool for the~static code analysis.

% =================================================================
% ============================= CHAPTER 4 =========================
% =================================================================
\chapter{The~.NET Compiler Platform}
In~the~.NET world, the~compiler used~to~be a~black box that given the~file paths to~the~source text, produced an~executable. This perception was changed in~2015 when Microsoft introduced the~.NET Compiler Platform (commonly referred to as \textit{"Roslyn"}).

Not only have been compilers for both Visual Basic and C\# rewritten into an~entirely managed code\footnote{The~term managed code refers to a~source code written in one of the~high-level programming languages available for use with Microsoft .NET Framework and require a~Common Language Runtime virtual machine in order to be executed.}, but they also expose the~internals of the~compiler pipeline via a~public .NET API. This makes them a~platform (also known as \textit{compiler-as-a-service}) with rich code analysis APIs that can be leveraged by developers to perform analysis, code generation, or dynamic compilation in their own programs~\cite{roslyn-succinctly}. Those can be then easily integrated into Visual Studio without the~hard work of duplicating compilers' parsing logic.

This chapter takes a~look at how the~Roslyn API layers are structured, how the~original source code is represented by the~compiler, and how developers can build tools upon the~compiler's API. Note, that although Roslyn provides equivalent APIs for both Visual Basic and C\#, this thesis only focuses on the~latter since it is relevant for the~practical part of the~thesis.  
  
\section{The~Compiler Pipeline}
The Roslyn compilers expose an~API layer that mirrors the~traditional compiler pipeline (see Figure~\ref{fig:roslyn-compiler-pipeline}). Instead of a~single process of generating the~target program, each compilation step is treated as a~separate component~\cite{roslyn-overview}:

\begin{itemize}
  \item \textbf{Parse phase} consists of \textit{lexical analysis} (\textit{scanner}) and \textit{syntactic analysis} (\textit{parser}). First, the~lexical analyzer processes the~stream of characters from the~source program and groups them into meaningful sequences called \textit{lexemes}. Those are subsequently processed by the~\textit{syntax analyzer} that creates a~tree-like structure of tokens based on the~language grammar~\cite{dragon-book}.

  \item \textbf{Symbols and metadata phase} where named symbols are generated based on the~declarations from the~source and imported metadata.

  \item \textbf{Bind phase} in which the~identifiers from the~source code are matched to their respective symbols.

  \item \textbf{Emit phase} where all the~gathered information is used to emit an~assembly.
\end{itemize}

\begin{figure}[h!]
		\centering
			\includegraphics[scale=0.85]{img/roslyn-compiler-pipeline}
		\caption{Compiler pipeline, adopted from~\cite{roslyn-overview}}
		\label{fig:roslyn-compiler-pipeline}
\end{figure}

In each phase, the~.NET Compiler Platform creates an~object model containing gathered information and exposes it through the~API in form of .NET objects. These objects are also used internally by Visual Studio~\footnote{The~new generation of Visual Studios leveraging from the~Roslyn compiler are called vNext and the~first one was VS 2015.} to support basic IDE functionality. For instance \textbf{syntax tree}, that is the~result of the~parse phase, is used to support formatting and colorizing the~code in the~editor. The~result of the~second phase -- \textbf{hierarchical symbol table}, is the~basis for \textit{Object browser} and \textit{Navigate~to} functionality. Binding phase is represented as an~\textbf{object model that exposes the~result of the~semantic analysis} and is utilized in \textit{Find all~references} or \textit{Go~to~definition}. Finally, the~Emit phase produces the~Intermediate Language (IL) byte codes and is also used for \textit{Edit and~Continue} feature~\cite{roslyn-overview}.

\section{The~.NET Compiler Platform's Architecture}
The~Roslyn's architecture consists of two main layers - Compiler and Workspaces APIs, and one secondary layer - Features API, as seen on Figure~\ref{fig:roslyn-compiler-architecture}.

\begin{figure}[h!]
		\centering
			\includegraphics[scale=0.85]{img/roslyn-compiler-architecture}
		\caption{.NET Compiler Platform Architecture, adopted from~\cite{roslyn-succinctly}}
		\label{fig:roslyn-compiler-architecture}
\end{figure}

One of the~key concepts of the~.NET Compiler Platform is immutability. The~compiler exposes hundreds of types that represent all information about the~source code from \texttt{Project} and \texttt{Document} to \texttt{SyntaxTree} with almost all of those types being immutable. This means, that once created, the~object cannot change. In order to alter it in any way, new instance must be created, either manually, or from an~existing instance by applying one of many \texttt{With()} methods that the~API provides.

The~immutability enables the~compiler to perform parallel work without need to create duplicate objects or applying any locks on them. This concept is useful for the~command line compiler but it is considered extremely important for IDEs where it enables for one document to be handled by multiple analyzers in parallel.

\subsection{Compiler APIs}
As discussed in the~previous section, the~Compiler APIs offer an~object model representing the~results of syntactic and semantic analysis produced by the~respective phases of the~compiler pipeline. Moreover, it also includes an~immutable snapshot of a~single compiler invocation, along with assembly references, compiler options, and source files. This layer is agnostic of any Visual Studio components, and as such can be used in stand-alone applications as well. There are two separate, though very similar, APIs for Visual Basic and C\#, each providing functionality tailored for specific language nuances.

\subsubsection{\textbf{Diagnostic APIs}}
Apart from parsing code and producing an~assembly, the~compiler is also capable of raising diagnostics, covering everything from syntax to semantics, and report them as errors, warnings or information messages~\cite{roslyn-succinctly}. This is achieved through the~compilers' Diagnostics APIs that allow developers to effectively plug-in to compiler pipeline, analyze the~source code using the~exposed object models, and surface custom diagnostics along with those defined by the~compiler itself. These APIs are integrated to both MSBuild~\footnote{The~Microsoft Build Engine \url{https://github.com/Microsoft/msbuild}} and Visual Studio (2015 and newer), providing seamless developer experience. Since the~practical part of~this thesis, and~both Chapter~\ref{chap:custom-roslyn-analyzers} and~\ref{chap:performance}, rely on~the~Diagnostic APIs to~provide custom diagnostics, they are discussed in~more detail in~Section~\ref{sec:analyzers-and-code-fixes}.

\subsubsection{\textbf{Scripting APIs}}
As a~part of the~compiler layer, Microsoft team has introduced new Scripting APIs that can be used for executing code snippets. These APIs were not shipped with .NET Compiler Platform 1.0 and are part of v2.0.0 RC3\footnote{Release candidate 3, as per \url{https://github.com/dotnet/roslyn/wiki/Scripting-API-Samples} [02/26/2017].}.

\subsection{Workspaces APIs}
Workspace represents a~collection of solutions, projects, and documents. It provides a~single object model containing information about the~projects in a~solution and their respective documents; exposes all configuration options, assembly and inter-project dependencies; and provides an~access to syntax trees and semantic models. It is a~starting point for performing code analysis and refactorings over entire solutions.

Although it is possible to use the~\texttt{Workspace} outside of any host environment, the~most common use case is an~IDE providing an~instance of \texttt{Workspace} that corresponds to the~open solution. Since the~instances of \texttt{Solution} are immutable, the~host environment must react to every event (such as user key stroke) with an~update of the~\texttt{CurrentSolution} property of the~\texttt{Workspace}.

\subsection{Feature APIs}
This layer relies on both compiler and workspaces layers and is designed to provide API for offering code fixes and refactorings. Features APIs were also utilized while working on the~practical part of this thesis.
  
\section{Syntax Tree}
As mentioned in the~previous sections, the~product of the~syntactic analysis is a~syntax tree. It enables developers to work with the~code in a~managed way instead of working against plain text. Syntax trees are used for both analysis and refactorings, where the~new code is generated either manually or as a~modified version of the~existing tree. While being immutable, syntax trees are thread-safe and analysis can be done in parallel.

It is important to point out, that in a~same way the~compiler constructs a~syntax tree from the~source text, it is also possible to round-trip back to the~text representation. Therefore, the~source information must be always preserved in full fidelity. This means that every piece of information from source must be stored somewhere within the~tree, including comments, whitespaces or end-of-line characters, which is a~major difference to the~general concept of compilers discussed in Chapter~\ref{chap:compilers}.

Figure~\ref{fig:roslyn-syntax-tree} shows a~syntax tree of an~invocation expression as obtained from Syntax Visualizer\footnote{\url{https://roslyn.codeplex.com/wikipage?title=Syntax\%20Visualizer}} extension available in Visual Studio. This tool is useful for understanding how Roslyn represents particular language constructs and is widely utilized whenever one needs to analyze the~code. Following sections explain what are the~main building blocks of such syntax tree, referring to Figure~\ref{fig:roslyn-syntax-tree}.

\begin{figure}[h!]
		\centering
			\includegraphics[scale=0.85]{img/roslyn-syntax-tree}
		\caption{Syntax tree of an~invocation expression}
		\label{fig:roslyn-syntax-tree}
\end{figure}

\subsubsection{\textbf{Syntax Nodes}}
Syntax nodes (blue color) are non-terminal nodes of a~syntax tree, meaning they always have at least one other node or token as a~child. Nodes represent syntactic constructs of a~language such as statements, clauses or declarations. Each type of node is represented by a~single class deriving from \texttt{SyntaxNode}. Apart from common properties \texttt{Parent}, \texttt{ChildNodes} and utility methods like \texttt{DescendantNodes}, \texttt{DescendantTokens}, or \texttt{DescendantTrivia}, each subclass exposes specific methods and properties. The \texttt{InvocationExpression} node has two properties, \texttt{IdentifierName} and \texttt{ArgumentList} both of which are \texttt{SyntaxNodes} themselves.
 
\subsubsection{\textbf{Syntax Tokens}}
As opposed to nodes, syntax token (green color) represent terminals of the~language grammar, such as keywords, punctuation, literals and identifiers. For the~sake of efficiency, \texttt{SyntaxToken} is implemented as a~value type (C\# structure) and there is only one for all kinds of tokens. To be able to tell them apart, tokens have \texttt{Kind} property. For example, \texttt{SomeFunction} is of kind \texttt{IdentifierName}, whereas "\texttt{(}" character is \texttt{OpenParenToken}.

\subsubsection{\textbf{Syntax Trivia}}
In order to enable refactoring features, syntax trees must also store information about whitespaces, comments and preprocessor directives that are insignificant for the~compilation process itself. This information is represented by another value type -- \texttt{SyntaxTrivia} (white color). Trivia are not really parts of the~tree itself, rather they are properties of tokens accessible by their \texttt{LeadingTrivia} and \texttt{TrailingTrivia} collections.

\section{Semantics of the~Program}
As explained in Chapter~\ref{chap:compilers}, even though syntax trees are enough to describe the~proper form of the~program (compliance to the~language grammar), they cannot enforce all language rules, for example type checking. In order to tell whether a~method is called with the~right number of arguments, or operator is applied to operands of the~right type, it is inevitable to introduce semantics. 

Its one of the~core compiler's responsibilities to populate symbol tables with information about all elements and their properties from the~source program. Attributes such as identifier name, type, allocated storage, scope; or for method names the~number and types of arguments and their return values; are all stored in order to be utilized later when producing the~intermediate language.

\subsubsection{\textbf{Symbols}}
In .NET Compiler Platform, a~single entry of a~symbol table is represented by a~class deriving from \texttt{ISymbol}. The~symbol represents every distinct element (namespace, type, field, property, event, method or parameter) either declared in the~source code or imported as metadata from a~referenced assembly. Each specific symbol has its own methods and properties often directly referring to other symbols. For example, \texttt{IMethodSymbol} has a~\texttt{ReturnType} property specifying what is the~type symbol the~method returns.

\subsubsection{\textbf{Compilation}}
An~important immutable type, that represents everything needed to compile a~C\# (or Visual Basic) program is a~\texttt{Compilation}. It contains all source files, compiler options and assembly references. The~compilation provides convenient ways to access any discovered symbol. For instance, it is possible to access the~entire hierarchical symbol table rooted by global namespace, or look up type symbols by their common metadata names.

\subsubsection{\textbf{Semantic Model}}
When analyzing a~single source file of a~compilation, all its semantic information is available through a~\textit{semantic model}. It can answer many questions such as:
  \begin{compactitem}
  \item What symbol is declared at the~specific location in the~source?
  \item What is the~result type of an~expression?
  \item What symbols are visible from this location?
  \item What diagnostics are reported in the~document?
  \end{compactitem}
 
This makes semantic model very useful when performing static code analysis concerned with more than just syntax.
 
\section{Analyzers and Code Fixes}
\label{sec:analyzers-and-code-fixes}
Thanks to the~Compiler APIs it is possible for Visual Studio to provide live static code analysis detecting any code issues as programmer types. Apart from general analyzers, that are shipped with Visual Studio, it is possible to define custom, domain specific rules. The~tricky tasks of running the~analysis on a~background thread, showing squiggles in the~IDE, populating the~\textit{Error List}, and providing the~\textit{light bulb} with code fix suggestions, is left to Visual Studio.

In order to understand the~chapters describing the~implementation part of the~thesis, it is vital to know how the~Diagnostic APIs work and how they are leveraged when writing a~custom analyzer.

\subsection{Diagnostic Analyzer}
As defined in~\cite{roslyn-succinctly}, an~analyzer is an~instance of a~type deriving from \texttt{Microsoft.CodeAnalysis.Diagnostics.DiagnosticAnalyzer} which must be annotated with \texttt{DiagnosticAnalyzer} attribute specifying the~targeted programming language (C\# or Visual Basic). In the~text of this thesis, these instances are referred to as \textit{end-analyzers}, in order to distinguish them from abstract analyzers or helper classes containing analysis logic. The~end-analyzer can contain one or more custom \textit{rules} for detecting domain specific errors or code issues. Each such rule is defined by \texttt{DiagnosticDescriptor}. Once the~analyzer finds an~issue, the~diagnostic descriptor is used to create a~\textit{diagnostic} which also includes data collected by the~compiler, such as location.

\subsubsection{\textbf{Diagnostic Descriptor}}
For any Roslyn end-analyzer it is mandatory to override an~immutable property \texttt{SupportedDiagnostics}. It returns an~immutable array of diagnostic descriptors which consist of:

\smallskip
\begin{compactitem}
  \item[\texttt{\textbf{DiagnosticId}}] -- unique value identifying a~single rule (e.g.~\textit{"BH103"}).
  \item[\texttt{\textbf{Title}}, \texttt{\textbf{MessageFormat}}, \texttt{\textbf{Description}}] -- localizable strings that will be displayed in the \textit{Error List}. The~message format can be also passed arguments upon diagnostic creation, to give more details about the~concrete issue detected.
  \item[\texttt{\textbf{Category}}] -- the~category that the~analyzer belongs to, such as code style, naming, design, etc. The~list of categories defined for this thesis can be found in Section~\ref{sec:analyzer-categories}.
  \item[\texttt{\textbf{DefaultSeverity}}] -- one of \texttt{Error}, \texttt{Warning}, \texttt{Info}, \texttt{Hidden}, \texttt{None}. Note, that only \texttt{Error} severity prevents the~project from compiling successfully.
  \item[\texttt{\textbf{IsEnabledByDefault}}] -- when this flag is set to \texttt{false}, the~rule must be turned on manually in the~rule set file.
  \item[\texttt{\textbf{HelpLinkUri}}] -- optional URI with an~online documentation.
\end{compactitem}

\subsubsection{\textbf{Performing the~analysis}}
The~analyzer needs to provide a~code that performs the~actual analysis (commonly referred to as \textit{action}). In order to tell the~.NET Compiler Platform when the action needs to be invoked, the~end-analyzer must register the~action by overriding the~\texttt{Initialize()} method. This method represents the~entry point of the~analyzer and is invoked exactly once per \textit{session}\footnote{For batch compilations the~session is a~single run of the~compiler. For hosted environments, where the~analysis runs on the~background thread, the~session can last as long as the~IDE is open. For more information see~\cite{analyzer-action-semantics}}. The~method accepts one argument, of type \texttt{AnalysisContext}, exposing number of methods for registering actions. Depending on when the~action should be invoked, a~callback with analysis logic is passed to one of these methods~\cite{analyzer-action-semantics}:

\smallskip
\begin{compactitem}
  \item[\texttt{\textbf{RegisterSyntaxNodeAction}}] -- the~action will be invoked on every syntax node encountered by the~compiler if the~kind of the~node matches one of the~kinds provided upon registration.
  
  \item[\texttt{\textbf{RegisterSymbolAction}}] -- the~action will be invoked on complete semantic processing of a~symbol that matches one of symbol kinds that the~action was registered with.
  
  \item[\texttt{\textbf{RegisterSyntaxTreeAction}}] -- the~action will be invoked as soon as the~whole document is parsed.
  
  \item[\texttt{\textbf{RegisterSemanticModelAction}}] -- the~action will be invoked after the~semantic analysis of the~document is finished.
  
  \item[\texttt{\textbf{RegisterCompilationStartAction}}] -- the~action will be invoked when the~compilation starts (before any other actions). The~context can be then used to register other actions within the~compilation as well as the~corresponding \texttt{RegisterCompilationEndAction}.
  
  \item[\texttt{\textbf{RegisterCodeBlockStartAction}}] -- the~action will be invoked before any of actions applicable within the~code block are invoked. The~matching \textit{code block end action} can be registered.
  
  \item[\texttt{\textbf{RegisterCompilationAction,}}] \texttt{\textbf{RegisterCodeBlockAction}} -- actions to be invoked once per~compilation or~code block, respectively.
\end{compactitem}

The~compilation or code block start actions are usually registered for so called \textit{stateful analyzers}. These report the~diagnostics about a~specific code unit, like a~syntax node or a~symbol (same as \textit{stateless analyzers}), but within the~enclosing unit of the~code block or the~compilation. They have to be designed carefully to perform effectively and not cause any memory leaks. For both categories of analyzers it is vital that they are written defensively and do not to throw any exceptions. Otherwise, Visual Studio might disable them.

\subsection{Code Fix Provider}
A code fix is a~quick action suggesting a~possible solution to a~diagnosed code issue found by the~analyzer. It can be applied by invoking the~quick actions (Ctrl+.) integrated into Visual Studio \textit{light bulb}. Before application, the developer can view a~live preview of the~code fix action, as depicted in Figure~\ref{fig:codefix-example}.

\begin{figure}[h!]
		\centering
			\includegraphics[scale=0.75]{img/codefix-example}
		\caption{A example of a~code fix live preview}
		\label{fig:codefix-example}
\end{figure}

A custom code fix can be defined by creating a~class deriving from \texttt{Microsoft.CodeAnalysis.CodeFixes.CodeFixProvider}. To declare which diagnostics it solves, the~\texttt{FixableDiagnosticIds} property must be overridden. The~logic of fixing the~diagnosed issue is placed in \texttt{RegisterCodeFixAsync} method, which ultimately generates a~new document.

\newpage
\subsection{Deployment}
There are two different approaches when it comes to deploying the~analyzers and code fixes: NuGet package, or Visual Studio extension. 

With the~IDE extension, every developer has to install it manually from Visual Studio Gallery\footnote{Visual Studio Gallery provides an~access to various tools that extend the~default Visual Studio functionality.}. Once installed, the~analysis is performed on any open project or solution. Therefore, it is only appropriate for analysis concerned with common language or framework guidelines.

On the~other hand, when the~analyzers are installed as a~NuGet package, only the~project that has them installed will be analyzed. The~reference to the~NuGet is stored in a~shared repository, and all developers working on the~project have the~analyzers installed automatically. Moreover, only the~NuGet installation influences the~compilation process and as such, can be run on the~build boxes as part of a~continuous integration (CI) process.

% =================================================================
% ============================= CHAPTER 5 =========================
% =================================================================
\chapter{Implementation of Custom Analyzers}
\label{chap:custom-roslyn-analyzers}
Kentico Software is an~IT company based in Brno, developing an~all-in-one solution for web content management, e-commerce, and online marketing, using the~ASP.NET\footnote{Open source framework for developing web applications by Microsoft.} architecture. Their leading product is Kentico CMS (Content Management System). It has been on the~market since 2004 with the~11th version currently being developed. 

Over the~course of almost 13 years, the~CMS solution grew to an~enormous extent. To give an~overview, the~current version contains 249 projects and a~total of 14,881 documents. A lot of knowledge was accumulated with many internal utilities developed and guidelines created. Many features, such as globalization, were developed in-house first, only to be added as an~integral part of the~.NET Framework a~few years later.

The~size of the~company grew to more than 80 developers working on one product. It became significantly harder to share all the~knowledge about the~internal best practices and the~process of onboarding new employees was challenging. With the~increasing complexity of the~project, the~main focus of the~code reviews was shifted to the~general architecture and inspection of how the~new code influences the~other parts of the~system, in order not to break anything. The~manual and often repetitive tasks of checking the~compliance with the~conventions and correct use of the~API during the~code review became very tiresome and dragged the~focus of the~reviewer away from the~higher perspective on the~code. This led to a~need for an~automated tool that would take care of the~repetitive checks that needed to be done by the~reviewer.

%company did not have the~motivation to invest too much into creating extremely complicated tool and at the~time (YYYY) it was very difficult to create something custom which would be robust and almost perfect at the~same time

%-  first attempts to rewrite BH to Roslyn 
%not so successful Bachelor thesis by another student (huge performance problems, implementation basically one to one with the~old console app, does not leverage of Roslyn type system, everything based on strings, therefore many missed diagnostic problems)

%why we are only concerned with this and do not check the~naming conventions or advanced refactoings - tools already exist for this (StyleCop and ReSharper) and were not implemented in new BH version - usings sorting and such is provided by other tools

% how ReSharper or StyleCop are used in Kentico
\section{The~Original BugHunter}
The~BugHunter is a~simple console application developed at Kentico that searches for violations of internal rules and best practices in the~CMS solution. Given the~file path to the~solution folder, the~BugHunter performs the~checks and outputs the~results to a~file. Each issue found is reported with a~short message plus additional an~information on its location in the~code (source file and line number). It contains various checks, not only for C\#, but also a~few for JavaScript (like no skipped tests allowed), ASPX\footnote{Active Server Page Extended is a~file format used in APS.NET framework.} (preferred usage of Kentico controls to default ones), or XML files.

The~following sections explain the~main downsides of the~original BugHunter and explains how this thesis addresses them.

\subsection{Need for Semantic Analysis}
The~biggest disadvantage of the~previous BugHunter was that the~tool performed the~checks purely by string comparison. It did not build any model of the~analyzed code, and, therefore, possessed no knowledge of the~semantics. 

This caused an~enormous number of false negatives. A typical example would be the~tool trying to prevent an~access to the~\texttt{Cookies} property of the~\texttt{HttpRequest} object. The~old BugHunter check looked something like this:

\begin{minted}[fontsize=\footnotesize]{csharp}
   if (line.Contains("Request.Cookies")) { /* report an error */ }
\end{minted}


If the~programmer used the~most common approach\footnote{Accessing the~static property of the~class that is handling the~request.} of accessing the~\texttt{Cookies} collection on the~\texttt{Request} object, everything was fine, and the~BugHunter correctly reported the~problem. However, it had no means of detecting other possible accesses to the~property. If the~\texttt{Request} object was passed to a~function as an~argument or stored in a~variable, the~accesses to the~cookies collection could not be detected by the~original BugHunter. 

There were other use cases that could lead to false negatives when using just primitive string comparisons. For example, in C\# it is allowed to put an~arbitrary number of whitespace characters between the~object, the~dot token, and the~property being accessed. This could have been solved by using a~bit more complicated regular expression, but it would still cover only a~fraction of use cases. Things like using a~variable or even an~alias using\footnote{\url{https://msdn.microsoft.com/en-us/library/aa664765(v=vs.71).aspx}} would stay undetected by the~tool. 

However, all the~above mentioned problems can be easily solved by introducing the~semantics into the~analysis. As discussed in chapters~\ref{chap:compilers} and~\ref{chap:static-code-analysis}, once the~source code is parsed, and both AST and symbol tables are available, the~analysis tool should have all the~information necessary for understanding the~analyzed source code. This approach is far superior to plain string matching performed by the~original BugHunter, and the~analyzers developed as part of this thesis leverage it thanks to Roslyn Diagnostic APIs.

\subsection{Ease of Use}
As mentioned in the~Chapter~\ref{chap:static-code-analysis}, the~key to success of a~static code analysis tool is the~ease of use. This means that running the~tool should not be complicated and interpreting the~results should be straightforward. If this is not the~case, programmers will not use the~tool at all or they will ignore the~results it produces. 

With the~original BugHunter, a~developer had to run the~separate application that took for about 30 seconds. Then, he or she had to analyze the~results before going back to the~IDE in order to look up the~reported issues and fix them. 

In a~discussion with the~developers at Kentico, they all admitted, that more often than not, they submitted the~changes to the~version control system without running the~BugHunter locally. 

The~console application was run by the~build server itself as part of the~continuous integration. If the~BugHunter detected any issues, the~developer who caused them would be notified by an~email and would have to fix them as part of the~no-warning policy. This process prolonged the~time it took to finish the~implementation and generated a~demand for a~more developer-friendly solution. 

Since Roslyn analyzers are part of Visual Studio IDE, programmers get an~instant feedback and see the~warnings before submitting the~code without the~need to run an~external application.

\subsection{Suppressing the~Results}
Another downside of the~previous solution was the~way certain portions of the~code were excluded from the~analysis. Since the~BugHunter is a~console application and the~CMS solution is completely independent of it, the~configuration had to be placed in BugHunter's installation directory. This was deemed as not transparent, as it was not clear, why in one file certain code was okay, whereas, in the~other, it was reported as an~issue, without taking a~look into a~huge configuration file.

Moreover, the~only way to exclude a~certain piece of code from the~analysis was to put the~whole file, in which it appeared, into the~configuration of the~rule to be suppressed. This way of configuration lacked the~granularity and was opaque. 

On the~other hand, Roslyn provides numerous ways to turn off a~certain rule for a~project, a~file, or even a~line of code. More information on which approach was taken when deploying the~analyzers can be found in the~Appendix~\ref{appendix:deployment}.

\section{Defining Analyzer Categories}
\label{sec:analyzer-categories}
The~\texttt{Category} property of the~\texttt{DiagnosticDescriptor} class (described in Section~\ref{sec:analyzers-and-code-fixes}) provides a~way for semantically distinguishing the~analyzers and giving additional information on what type of problem the~particular category is concerned with. The~original BugHunter did not group the~checks into the~semantic categories, but was structured rather by the~technology targeted by the~check (C\#, ASPX, JavaScript, web parts, etc.). 

Therefore, one of the~first tasks before the~implementation was to determine which checks are suitable candidates for refactoring into new Roslyn analyzers and subsequently group them into categories by the~type of the~task they performed. Basically, all the~checks that were not obsolete and were concerned with C\# internal guidelines were rewritten. Table~\ref{tab:analyzer-categories-compact-table} lists all implemented analyzers sorted into categories and following sections briefly elaborate on how the~categories were defined and what they represent. 

% ------------------ Summary Table ------------------
\begin{table}
\resizebox{1.005\textwidth}{!}{%
\begin{tabularx}{1.038\textwidth}{ll}
\toprule
\textbf{Category} & \textbf{Analyzer name} \\ \hline

\midrule
\textbf{AbstrOverImpl}
  & LuceneSearchDocumentAnalyzer \\

\textbf{CmsApiReplacements}
  & HttpSessionSessionIdAnalyzer \\
  & HttpSessionElementAccessAnalyzer \\
  & HttpRequestCookiesAnalyzer \\
  & HttpResponseCookiesAnalyzer \\
  & HttpRequestUserHostAddressAnalyzer \\
  & HttpRequestUrlAnalyzer \\
  & HttpRequestBrowserAnalyzer \\
  & HttpResponseRedirectAnalyzer \\
  & HttpRequestQueryStringAnalyzer \\
  & PageIsCallbackAnalyzer \\
  & PageIsPostBackAnalyzer \\
  & FormsAuthenticationSignOutAnalyzer \\
  & ClientScriptMethodsAnalyzer \\
  & SystemIOAnalyzer \\

\textbf{CmsApiGuidelines}
  & WhereLikeMethodAnalyzer \\
  & EventLogArgumentsAnalyzer \\
  & ValidationHelperGetAnalyzer \\
  & ConnectionHelperExecuteQueryAnalyzer \\
 
\textbf{CmsBaseClasses}
  & ModuleRegistrationAnalyzer \\
  & WebPartBaseAnalyzer \\
  & PageBaseAnalyzer \\
  & UserControlBaseAnalyzer \\

\textbf{StringAndCulture}
  & StringManipulationMethodsAnalyzer \\
  & StringEqualsMethodAnalyzer \\
  & StringCompareToMethodAnalyzer \\
  & StringStartAndEndsWithMethodsAnalyzer \\
  & StringIndexOfMethodsAnalyzer \\
  & StringCompareStaticMethodAnalyzer \\
\bottomrule
\end{tabularx}
}
\caption{Analyzers sorted into categories}
\label{tab:analyzer-categories-compact-table}
\end{table}
% ---------------------------------------------------

\subsection{Abstraction over Implementation}
Analyzers in this category check that there is no \textit{hard reference} on third party libraries in the~code. Violation of this rule would require clients to use a~particular version of the~library which might collide with the~references on other components they are using, resulting in so-called \textit{dependency hell}, described in~\cite{dependency-hell}. Therefore, in CMS solution the~hard references are replaced with a~thin layer of interfaces and adapters. The~analyzers make sure, only the~interfaces are used throughout the~solution.

\subsection{CMS API Replacements}
In CMS solution, there are many helpers encapsulating the~traditional .NET API and providing an~extended functionality. For example, determining the~current browser of the~user can be done by accessing the~\texttt{Browser} property of the~\texttt{HttpRequest} object. However, if this attempt fails, there are still other ways to resolve it and the~CMS API typically has a~helper class for such cases. The~analyzers detect accesses to members that have a~CMS~equivalent and suggest code fixes. 

\subsection{CMS API Guidelines}
These analyzers impose internal guidelines on the~CMS API usage. They forbid the~direct access to~the~database from presentation layer, point out usages of methods that may have more suitable or safer alternatives, or guide developers to use predefined constants where possible.

\subsection{CMS Base Classes}
Similar to \textit{CMS API Replacements} category, the~analyzers search for classes that inherit from standard .NET classes with CMS alternatives, and suggest the~correct CMS replacements.

\subsection{String and Culture}
This category of analyzers makes sure that string comparison\footnote{\texttt{Equals()}, \texttt{Compare()}, \texttt{IndexOf()} and their variants} and manipulation\footnote{\texttt{ToLower()}, \texttt{ToUpper()}} methods are always used with the~overload specifying \texttt{StringComparison} or \texttt{CultureInfo} parameter explicitly. This is vital for an~application like CMS that is used with culture specific data. For more information on what issues can be caused when not following this rule, see \cite{best-practices-for-using-strings-in-dot-net}. 

\section{Strategy Classes for API Replacement Analyzers}
The~\textit{CMS API Replacements} category contains 15 analyzers which represents more than one half of total 29 analyzers that were created. Vast majority of these analyzers searches for a~particular member being accessed or invoked on a~particular type. Any such usage found by the~analyzer shall be reported as CMS API contains a~replacement for it, with a~code fix suggested where applicable.

In order to prevent code duplication and ease the~process of adding new analyzers, the~analysis logic for analyzers in this category was extracted into two strategy classes\footnote{\url{http://www.oodesign.com/strategy-pattern.html}}: \texttt{ApiReplacementForMemberAnalyzer} and \texttt{ApiReplacementForMethodAnalyzer}. These are instantiated and configured by the~concrete end-analyzer to perform the~analysis on their behalf.

\subsection{Configuration}
There are only a~few things the~API replacement analyzer needs to know in order to perform the~actual analysis. This information is encapsulated in \texttt{ApiReplacementConfig} object. The~object is passed as a~constructor argument upon creation of the~API replacement analyzer. It contains following properties:

\begin{itemize}
  \item \texttt{ForbiddenMembers} -- member names to look for (e.g. \texttt{"Cookies"}).
  \item \texttt{ForbiddenTypes} -- names of fully qualified (super)types the~members belong to\footnote{The~forbidden type is treated as the~highest type in the~inheritance hierarchy the~member could belong to.
} (e.g. \texttt{"System.Web.HttpRequest"}), 
  \item \texttt{Rule} -- an~instance of \texttt{DiagnosticDescriptor} that defines the~diagnostic raised upon detection of a~forbidden usage.
\end{itemize} 

The~main reason behind \texttt{ForbiddenTypes} being an~array of strings rather than a~single string, is the~lack of inheritance hierarchy between \texttt{HttpRequest} and \texttt{HttpRequestBase} objects in the~.NET framework. They basically contain the~same members but do not derive from one another\footnote{More information on why this is so can be found in \url{https://msdn.microsoft.com/en-us/library/system.web.httprequestwrapper.aspx}} and therefore, the~analyzer must treat both types separately. 

On the~other hand, allowing for multiple forbidden members on one type under one diagnostic ID may also make sense, which is why \texttt{ForbiddenMembers} are defined as an~array, as well.

\subsection{Analyzer for Member Replacement}
The~task for the~\texttt{ApiReplacementForMemberAnalyzer} is to subscribe to all possible member accesses and analyze them. If the~particular access is regarded as forbidden, given the~configuration supplied (\texttt{ApiReplacementConfig} object), the~analyzer raises a~diagnostic.

Subscribing only to nodes of \texttt{SimpleMemberAccessExpression} syntax kind is not enough for the~analyzer. It also needs to analyze the~\texttt{ConditionalAccessExpression} (\texttt{"?."}, so-called \textit{null conditional operator}) which is a~new C\# 6.0 language feature\footnote{\url{https://msdn.microsoft.com/en-us/library/dn986595.aspx}}. 

Even though it would be possible to subscribe to both kinds of syntax nodes with one callback, the~underlying syntax of these two is so much different, it would make the~code cluttered and full of \textit{if-statements}. Moreover, if Microsoft decides to add another possibility to access members in the~next language version, the~existing code would have to be modified.

Therefore, the~strategies for analyzing a~particular syntax node were encapsulated into separate classes. The~member replacement analyzer instantiates the~strategy helpers, configures them, and tells them to run the~analysis methods as callbacks subscribed syntax node of a~particular kind. This makes the~code easily extendible.

\begin{figure}[h!]
		\centering
			\includegraphics[scale=0.8]{img/uml/api-replacement-for-member}
		\caption{Class diagram of \texttt{ApiReplacementForMemberAnalyzer}}
		\label{fig:uml-api-replacement-for-member}
\end{figure}

The~UML class diagram for \texttt{ApiReplacementForMemberAnalyzer} is depicted in Figure~\ref{fig:uml-api-replacement-for-member}. Note, that the~\texttt{DiagnosticAnalyzer} is an~abstract class defined in the~.NET Compiler Platform Diagnostics API and must be extended by the~custom end-analyzers.

\subsection{Analyzer for Method Replacement}
The~class \texttt{ApiReplacementForMethodAnalyzer} is very similar to analyzer for members that was introduced in the~previous section. It also accepts a~configuration object defining the~invocations of which members on which types are forbidden. 
Instead of subscribing to member accesses, it is interested in \texttt{InvocationExpression} syntax nodes. It delegates the~analysis itself to another strategy class defined in the~following section -- \texttt{MethodInvocationAnalyzer}.

\section{Strategy for Method Invocation Analysis}
An~algorithm for analyzing invocation expression syntax nodes is defined by~\texttt{MethodInvocationAnalyzer}. The~need for analyzing the~method invocations is not limited to the~API replacements. The~same analysis needs to be performed when enforcing internal guidelines that are concerned with methods. It is important to locate the~specific methods invoked on specific types, before it is possible to analyze further whether or not they are used according to the~internal API conventions. 

\subsection{Template Method Pattern}
This analyzer is utilized by all end-analyzers that involve method invocation analysis. In order to be easily extendible for advanced checks, it is implemented as a~template method pattern\footnote{\url{http://www.oodesign.com/template-method-pattern.html}}. Every step of the~template method defines a~criteria that must be met in order for the~analysis to proceed. Steps that can be overridden have default implementation that continues with the~analysis. 

It is important to note that the~steps are ordered in a~way so that the~inexpensive checks are performed first, in order to cut off the~analysis of the~irrelevant nodes without significant performance costs. Figure~\ref{fig:uml-method-invocation-analyzer} shows the~class diagram of the~\texttt{MemberInvocationAnalyzer} depicting the~use of template method design pattern. Following sections elaborate on the~respective steps of the~algorithm. Concrete use case depicting an~instance of the~analyzer can be seen in Figure~\ref{fig:uml-method-invocation-analyzer-object-diagram}.  

\begin{figure}[h!]
		\centering
			\includegraphics[scale=0.85]{img/uml/method-invocation-analyzer}
		\caption{Class diagram of \texttt{MethodInvocationAnalyzer} depicting the~template method design pattern}
		\label{fig:uml-method-invocation-analyzer}
\end{figure}

\subsubsection{\textbf{Check the~File Path}}
Sometimes, an~analyzer needs to pre-filter files that are relevant for the~diagnostic. For example, when looking for an~access to the~database layer from the~presentation layer, the~analyzer is only concerned with the~invocation expressions in the~files of presentation layer. These can be identified by inspecting the~\texttt{FilePath} property of the~\texttt{SyntaxTree} in which the~current invocation expression is located. If the~file path does not meet the~requirements, the~current invocation expression does not need to be analyzed further.

\subsubsection{\textbf{Method Name Syntax Analysis}}
This step exists purely for performance optimization reasons and cannot be overridden by subclasses. It tries to extract the~name of the~invoked method, and compares it to the~forbidden members. If the~method name is not among the~forbidden members, the~algorithm stops and no expensive operations had to be done. Otherwise, the~algorithm advances to the~next step.

Since there are no constraints on kinds of syntax nodes that could be children of the~\texttt{InvocationExpressionSyntax} node, the~logic had to be implemented by hand. The~heuristic inspects these three cases:
\begin{compactitem}
  \item[\texttt{IdentifierName}] -- the~simplest case where the~method being invoked is a~member of the~enclosing class.
    
  \item[\texttt{SimpleMemberAccessExpression}] -- invocation on member that is being accessed on object, or class. Accesses can be possibly chained.    

  \item[\texttt{ConditionalAccessExpression}] -- similar to the~previous case but the~access is conditional. The~whole syntax tree is right-folded as opposed to the~simple member access left-folded syntax tree. 
\end{compactitem}

\subsubsection{\textbf{Method Name and Receiver Type Semantic Analysis}}
In this step, the semantic model is queried for an~\texttt{IMethodSymbol} matching the~analyzed \texttt{InvocationExpressionSyntax}. If the~method symbol is found, its \texttt{Name} property is compared to forbidden member names. If the~check passes, the~property \texttt{ReceiverType} is inspected and only if it is one of forbidden (sub)types, the~algorithm proceeds. 

This method cannot be overridden as it is the~integral part of the~whole algorithm. It is also the~most expensive one, since the~checks in this method are performed on symbols obtained by querying the~semantic model. However, thanks to the~heuristics from the~previous step, the~majority of irrelevant cases was already filter out.

\subsubsection{\textbf{Context of the~Invocation Usage}}
If it is important to analyze the~context of the~invocation usage (mainly supplied arguments), the~subclass can override \texttt{IsForbiddenUsage()} method. The~template method supplies it with two parameters: the~invocation expression and the~method symbol obtained in the~previous step.

\subsubsection{\textbf{Diagnostic Creation}}
If all the~steps above determined that the~analyzed invocation is forbidden, the~last step of the~template method makes sure the~diagnostic is raised, using the~diagnostic descriptor provided upon creation. It is possible to configure the~diagnostic creation by providing optional instance of \texttt{IDiagnosticFormatter}. It is an~interface defined in the~\textit{BugHunter} project that constructs a~correctly formatted diagnostic (mainly its location and message text) for certain syntax nodes.

\subsection{Usage}
\label{sec:method-invocation-analyzer-usage}
The~\texttt{EventLogArgumentsAnalyzer} is a~prime example on how to use this template method, see~Figure~\ref{fig:uml-method-invocation-analyzer-object-diagram}. It defines an~inner class that subclasses the~\texttt{MethodInvocationAnalyzer}, and redefines one step of the analysis algorithm by overriding the  \texttt{IsForbiddenUsage()} method.

Then, this inner class is utilized by the~end-analyzer to perform the~analysis. Upon instantiation the~end-analyzer provides it with~a~configuration object and a~custom diagnostic formatter. 

\begin{figure}[h!]
		\centering
			\includegraphics[scale=0.75]{img/uml/method-invocation-analyzer-object-diagram}
		\caption{Object diagram of \texttt{EventLogArgumentsAnalyzer} using inner class deriving from \texttt{MethodInvocationAnalyzer}}
		\label{fig:uml-method-invocation-analyzer-object-diagram}
\end{figure}

\subsection{Analyzers for String and Culture Checks}
\label{sec:string-and-culture-approach-explained}
The~analyzers in \textit{String and Culture} category search for methods like \texttt{Equals()}, \texttt{CompareTo()}, or \texttt{IndexOf()}. Considering that the methods with same names can be found on many other types as well (\texttt{Object}, \texttt{Collection}), the~first syntax check for method name will often fail to filter out the~unrelated usages. Although all these analyzers could use the~\texttt{MethodInvocationAnalyzer} as a~strategy, a~different approach was applied here. 

The~need of only analyzing the~invocations on \texttt{String} type, makes the~analysis of forbidden types in \texttt{MethodInvocationAnalyzer} unnecessarily complex. String is a~sealed class\footnote{Sealed classes cannot be subclassed.} and so, no complicated traversal of inheritance hierarchy is needed. In fact, in C\# strings are a~\textit{special type} and therefore, only a~simple check like this is sufficient:

\begin{minted}{csharp}
  receiverType.SpecialType == SpecialType.System_String
\end{minted}

\section{Code Fixes}
\label{sec:code-fixes}
All analyzers that were implemented provide one or more code fixes. There are only two exceptions:
\begin{itemize}
  \item \texttt{SystemIoAnalyzer}, since there is no one to one mapping between \texttt{CMS.IO} and \texttt{System.IO} APIs, it is not feasible to provide a~code fix in every situation,

  \item \texttt{ConnectionHelperExecuteQueryAnalyzer}, which a~detects database access from presentation layer that points out a~possible design flaw without an~automated solution.
\end{itemize} 

% TODO consider deleting this
The~code fixes have one significant limitation -- providing a~fix to an~API replacement when the~forbidden access is conditional. This is due to the~nature of the~C\# grammar and the~way how null conditional operator is represented in the~syntax tree. If the~access is chained, it would be very difficult to define the~exact part of the~syntax tree that should be replaced. In fact, there is even an~issue\footnote{\url{https://github.com/dotnet/roslyn/issues/3110}} on GitHub of the~Roslyn team explaining in detail why this is problematic. 

Therefore, it was decided not to provide the~code fix in such complicated cases. There were two options how to prevent the~code fix from being suggested. The~first one was to give the~diagnostic on conditional access a~different diagnostic id from the~easily-fixable member access. This was deemed as not particularly user friendly and other options were sought.

The~approach taken was to provide an~additional information to the~diagnostic via the~\texttt{Properties} property\footnote{\url{http://www.coderesx.com/roslyn/html/93197CDD.htm}}. It is a~data structure were arbitrary key-value pairs can be stored when diagnostic is raised and can be later read in the~code fix class. The~analyzer stores a~flag, telling that the~diagnostic is raised for conditional access. When the~code fix method is invoked, it can decide whether or not it is capable of providing a~fix for the~diagnosed node.

\section{Tests}
Since it is infeasible to test the~functionality of all the~analyzers manually by running Visual Studio, it is crucial that all the~requirements are covered by an~automated set of tests. 

Every analyzer and its code fixes have an~extensive suite of tests covering the~functionality. The~extension methods and helper classes are covered by separate unit tests as well. The~pre-generated boilerplate from Visual Studio for testing analyzers was reused and rewritten using NUnit framework~\footnote{Testing framework for .NET languages \url{https://www.nunit.org}}. Since the~default template did not allow to set anything apart from the~sources, it had to be customized and some additional features were added.

A typical scenario for testing an~analyzer is to:
\begin{compactenum}
  \item Prepare the~source documents to be tested. Typically one C\# class stored in a~string.
  \item Create a~compilation out of the~source documents.
  \item Run the~analyzer under test on the~compilation.
  \item Compare the~output of the~analyzer with the~expected diagnostics.
\end{compactenum}

To test the~code fix, it is run on the~source containing a~diagnostic and the~document with applied code fix is compared to the~expected result.

\subsubsection{\textbf{Referencing Kentico Libraries in Tests}}
As can be seen, when testing analyzers and code fixes, the~compilation is always created from the~source documents. For this to work, all references to the~libraries used by the~source code, or relied upon by the~tested analyzer, need to be linked. This contains not only the~Microsoft core assemblies that are always added, but in case of the~BugHunter analyzers, also Kentico libraries. Therefore, the~default testing template had to be enhanced with the~ability to explicitly reference desired DLLs\footnote{Dynamically Linked Libraries} in the~created compilation.

\subsubsection{\textbf{Faking File Information of Documents in Compilation}}
The~outcomes of some analyzers are dependant on the~file path of the~analyzed document. Therefore, to test them, it is necessary to be able to fake the~name of the~source document that will be part of the~analyzed compilation. To accommodate this requirement, the~testing template was extended with \texttt{FakeFileInfo} structure. It can be passed as an~optional argument to the~function testing the~analyzers, in order to replace the~default file name, path, or extension.

\subsubsection{\textbf{Failing Tests on Uncompilable Sources}}
Another important feature, that was not present in the~Microsoft template is, that when the~source documents are uncompilable (e.g contain a~typo), the~tests will fail, no matter if the~analyzer and/or code fix worked as expected. Since the~compilers generally, and, therefore, also the~analyzers themselves, are heavily reliant on string constants, it is very important to have this kind of check present.

Failing the~test upon uncompilable tested source was added later in the~development and it uncovered quite a~few errors. Some of them were rooted back in the~original BugHunter. For example it checked for \texttt{HttpRequest.Redirect()} which actually does not exist, because \texttt{Redirect()} method is a~member of \texttt{HttpResponse} object, not \texttt{HttpRequest}.

\subsubsection{\textbf{Tracking the~CMS API Changes}}
In order to supply the~Kentico DLLs to be referenced in the~tested on-demand compilation, the~test projects have a~dependency on \textit{Kentico.Libraries} NuGet package. This, together with tests failing on uncompilable source, has a~very pleasant side effect: It tracks any breaking changes in CMS API that affect the~analyzers' or code fixes' logic.

For instance, if some method from the~Kentico API changes the~number of arguments, code fix, that introduces the~method to the~source code, is invalid and its tests will fail. They will also provide a~detailed compiler error message, so that the~developer knows instantly what issues need to be fixed after the~upgrade.

Only major versions can contain a~breaking change and these are released once a~year in Kentico. To keep the~BugHunter analyzers up to date, the~referenced NuGet should to be upgraded regularly.

\bigskip\noindent
This chapter presented selected implementation details and patterns utilized during the~development. The~next chapter focuses on~the~performance aspect of~the~tool. It describes how the~performance of~the~analyzers was measured and what was done in~order to~enhance it. It also assesses the~tool's usability based on feedback obtained from the~Kentico development team.

% =================================================================
% ============================= CHAPTER 6 =========================
% =================================================================
\chapter{Measuring and Optimizing the~Performance}
\label{chap:performance}
When implementing custom Roslyn analyzers, it is vital to consider their performance. The~analyzers run on a~background thread of Visual Studio (or parallel threads of compilation process, when outside of the~IDE) and if implemented carelessly, they might significantly influence the~processing power and the~memory consumption.

This holds for any custom analyzers written, but even more so if they are to be used with large solutions like Kentico CMS. Developers at Kentico expressed concerns about the~responsiveness of Visual Studio with an~opened CMS solution. Some had even uninstalled the~ReSharper extension, since it slowed down the~IDE to an~unbearable extent and often caused it to crash. 

Therefore, in order for the~BugHunter analyzers to be usable, they have to be efficient. This chapter explains how the~performance of the~implemented analyzers was measured and provides a~quick look at their optimizations. The~final part of the~chapter summarizes views of Kentico development team on the~usability of new BugHunter.

\section{CMS Solution Size}
Before discussing the~performance of the~BugHunter analyzers, it is important to understand the~structure of the~CMS solution. This is helpful when considering which parts of the~analyzers' code are crucial for the~overall performance and which are not as critical.

In order to collect relevant information, \textit{SolutionStatistics} project was created (the source code can be found in the~IS attachment). The~project loads the~CMS solution and collects information on number of projects, documents, syntax nodes. The~summary of the~results is presented in Table~\ref{tab:solution-statistics}. Note, that just the~data relevant for implemented analyzers are displayed. Therefore, only projects where NuGet with BugHunter analyzers is installed\footnote{Test and 3rd party projects were excluded from statistics, see Appendix~\ref{appendix:deployment}.} and relevant kinds of syntax nodes are considered.

% ------------------ Solution Statistics Table ------------------
\begin{table}
\begin{tabularx}{\textwidth}{Xr}
\toprule
Number of projects                  & 125 \\
Number of documents              & 11,136 \\
Number of syntax nodes        & 6,279,993 \\
- IdentifierNameSyntax        & 1,422,571 \\
- MemberAccessExpressionSyntax  & 350,942 \\
- InvocationExpressionSyntax     & 216,716 \\
- ObjectCreationExpressionSyntax & 22,635 \\ 
- ElementAccessExpressionSyntax  & 17,930 \\
- ClassDeclarationSyntax         & 10,288 \\ 
- ConditionalAccessExpressionSyntax & 482 \\

\bottomrule

\end{tabularx}
\caption{Statistics about the~projects with installed analyzers}
\label{tab:solution-statistics}
\end{table}
% ---------------------------------------------------

\section{Measuring the~Performance}
The~goal of the~performance measurements done in this thesis was to evaluate the~effectiveness of implemented analyzers, in order to spot and eliminate possible anomalies in the~implementation, and assess the~overall impact of the~analyzers on the~length of MSBuild.

In the~early stages of development, the~idea was to compute benchmarks for different analyzer versions using \textit{BenchmarkDotNet} framework\footnote{\url{https://github.com/dotnet/BenchmarkDotNet}}. However, the~overhead of creating the~compilation made it virtually impossible to extract only the~relevant information from the~obtained results.

The~challenge of measuring the~performance of Roslyn analyzers lies in the~fact, that their execution is tightly coupled with the~compilation process of the~project they are installed to. Therefore, it is difficult to measure the~exact execution time from the~outside. 

Before considering the~overall impact of BugHunter analyzers on the~compilation of the~CMS solution, it was important to tune the~performance of separate analyzers. There seem to be no third-party tools for measuring analyzers performance at the~time of writing. The~final approach for measuring their execution times was to rely on the~only official option -- \texttt{/ReportAnalyzer} compilation switch. In~order to minimize the~impact of any outliers, the~measurement was repeated multiple times. The~procedure is described in greater detail in the~following section. The~impact of the~analyzers on total build time is discussed in Section~\ref{sec:build-times}.

All the~measurements were done on a~desktop computer with 16~GB of~RAM, Intel~i5~quad-core processor (3.5~GHz) and SSD disk -- same as all developers at Kentico work on. 

\subsection{Performance of Separate Analzyers}
The~only way that Microsoft provides for measuring the~analyzers' execution times is \texttt{/ReportAnalyzer} switch in CSC (CSharp Compiler). As stated in~\cite{report-analyzer}, if the~compiler is invoked with \texttt{/ReportAnalyzer} command line switch, its output will contain total wall clock time spent in executing the~analyzers along with the~absolute and the~relative times of separate analyzers. Since the~analyzers can run concurrently, the~total time should only be treated as the~upper bound. The~relative times per analyzer are useful for comparing their performance and identifying any outliers.

In order to compile the~whole solution, one must use the~MSBuild process, that internally uses the~CSC.
The~command, that also reports the~execution times, looks like this\footnote{Note, that the~official documentation (\url{https://msdn.microsoft.com/en-us/library/ms164311.aspx}) does not provide any information on running the~MSBuild with reporting the~analyzers. The~only approach that worked was the~one shown above. The~verbosity level set to \textit{diagnostic} is vital here, since \textit{verbosity:debug} completely omitted any information on analyzer reporting.}:

\begin{center}
\texttt{msbuild /t:Clean,Build /p:ReportAnalyzer=True /verbosity:diagnostic CMS.sln}
\end{center}

\subsubsection{\textbf{Parsing and Aggregating Per-project Results}}
The~size of the~resulting MSBuild output is over 500MB and, besides normal compiler output, it contains information on analyzers' execution times for every project that the~analyzers' NuGet is installed~to. For the~CMS solution this means 125 projects. For the~purpose of this thesis, however, only performance over~the~whole solution is relevant. 

In order to parse the~results from the~large output, a~console application \textit{ReportAnalyzerTimes.Parser} was developed. It extracts all data related to the~analyzers' execution times from the~log (based on the~format described in~\cite{report-analyzer}). After that, it sums up the~absolute execution times\footnote{The~smallest value, that can be reported, for the~execution time is \textit{<0.001s} and it is treated as \textit{0.001s} by the~parsing application.} for same analyzers across the~solution (sums per-project results) and outputs them into a~file.

\subsubsection{\textbf{Aggregating Results from Multiple Runs}}
Since a~single compiler run should not be relied upon to provide accurate results, a~PowerShell script (\textit{Report-Analyzer.ps1}, see Figure~\ref{fig:uml-report-analyzer-dfd}) was written that executes the~CMS solution MSBuild multiple times. After every run, it runs the~above mentioned \textit{ReportAnalyzerTimes.Parser} application on the~compiler output, and results from all runs are saved in multiple text files. 

Once the~predefined number of builds was completed, another console application, \textit{ReportAnalyzerTimes.Aggregator}, is used to aggregate the~results into a~single CSV\footnote{Comma Separated Values} file. For every analyzer, there is a~name and the~accumulated per-project execution times from every run of the~solution's build.

\begin{figure}[h!]
		\centering
			\includegraphics[scale=0.98]{img/uml/report-analyzer-flow}
		\caption{Diagram for \textit{Report-Analyzer.ps1} script.}
		\label{fig:uml-report-analyzer-dfd}
\end{figure}

\section{Optimizations}
The~procedure described in the~previous section was used to measure and compare the~performance of implemented analyzers. The~measurements were performed directly on the~CMS solution.

The~slowest analyzers were iteratively optimized and the~speed of different versions was also compared using the~\textit{Report-Analyzer.ps1} script. The~versions that performed the~best where then integrated into the~final NuGet package.

Some of the~optimizations were already briefly mentioned in the~previous chapter: customized approach for analyzers in \textit{String and Culture} category instead of generic \texttt{MethodInvocationAnalyzer}; or the~syntax heuristics utilized in \texttt{MethodInvocationAnalyzer}. This section presents the~iterative process of optimizing \texttt{SystemIOAnalyzer}, as well as its final version.

\subsection{Optimizing the~SystemIOAnalyzer}
After the~initial versions of all analyzers were implemented, the~first measurements showed that \texttt{SystemIOAnalyzer} is by far the~slowest one. It took more than 18 seconds to run on the~CMS solution, whereas almost all other analyzers executed in less than 0.3 seconds.

This analyzer belongs to the~\textit{CMS API Replacement} category and the~motivation behind its existence is described in~\cite{system-io-motivation}. It forbids the~access to all members from \texttt{System.IO} namespace, with an exception of \texttt{System.IO.Stream} and \texttt{System.IO.IOException} classes (and their subclasses), plus \texttt{System.IO.SeekOrigin} enumeration\footnote{All other members of the~namespace have CMS equivalents which must be used instead to make sure all parts of the~product can work with virtual file systems (like  Azure or Amazon storage).}.

\subsubsection{\textbf{Differences from Other CMS API Replacement Analyzers}}
What makes this analyzer fundamentally different from all other analyzers in its category is, that instead of blacklisting particular members or methods from Microsoft API, it forbids the~whole namespace (all classes, enums, methods, members, etc.) apart from few whitelisted, well defined, exceptions. Other analyzers in the~\textit{CMS API Replacement} category can reliably cut off the~analysis by looking at syntax and inspecting the~name of an~accessed member or method. Since only certain names are considered forbidden, vast majority of nodes will only be analyzed on the~syntax level. 

However, it would be infeasible for \texttt{SystemIOAnalyzer} to list all possibilities of forbidden API usage. Therefore the~analyzer needs to advance to perform more complicated and expensive analysis on symbols. It analyzers whether the~symbol is defined in \texttt{System.IO} namespace and whether it is not whitelisted. Only then it raises the~diagnostic.

Unlike other analyzers in the~category, that are bound to member access expressions or invocation expressions, the~\texttt{SystemIOAnalyzer} must inspect all syntax nodes of kind \texttt{IdentifierName}. As seen in Table~\ref{tab:solution-statistics}, there are more than 1.4 million such nodes. With the~naive implementation that directly accesses the~semantic model, the~performance of the~analyzer degrades very quickly. The~next two sections explain how the~optimization of the~analysis algorithm was achieved.

\subsubsection{\textbf{Different versions of SystemIOAnalyzer}}
The~very first version of the~analyzer (hereafter referred to as \textit{V1}), had an~action registered on syntax nodes of kind \texttt{IdentifierName}. It accessed the~semantic model straight away in order to perform the~analysis on symbols. The~\textit{V1} took more than 18 seconds to run on the~CMS solution.

First optimization attempts were to register the~syntax node action within the~compilation start action. The~fastest version with this approach collected all diagnosed nodes in a~collection. In the~compilation end action, the~diagnostics were raised for all collected nodes in a~parallel \textit{for-loop}. On average, this version of the~analyzer performed almost 2-times faster than the~\textit{V1}.

However, as pointed out by Roslyn development team on the~official GitHub repository~\cite{compilation-end-action-1, compilation-end-action-2}, registering compilation start and its end action, can cause problems for large solutions. This holds particularly for live IDE analysis. Not only can be the~analyzer's feedback delayed by several minutes, it might also lead to stale diagnostics in the~\textit{Error list} window.

The~next optimization approach was to minimize the~number of actions that need to be invoked. The~analyzer must inspect all 1.4~million identifier name nodes. It can either register its action on the~syntax node of this kind, as the~previous versions did, or register a~syntax tree action and look for identifier names on its own. This reduces the~number of callbacks to at most 11,136 (number of documents). 

The~logic, however, is more complicated, as the~tree needs to be traversed in order to find the~nodes to be inspected. On the~other hand, if the~document does not contain string \textit{".IO"} at all, there will be no diagnostic and its analysis can be skipped. For the~fastest version with syntax tree action the~analysis took over 9~seconds. Even though it was faster than the~\textit{V1}, it was still not ideal.

\subsubsection{\textbf{The~Final Version}}
\begin{figure}
		\centering
			\includegraphics[scale=0.98]{img/uml/system-io-activity-diagram}
		\caption{Activity diagram of \texttt{SystemIOAnalyzer} action}
		\label{fig:uml-system-io-activity-diagram}
\end{figure}

None of the~versions described above provided a~significant performance improvement compared to \textit{V1}. To understand the~limitations of the~analysis, two artificial analyzers were created, that registered an~action on identifier name syntax nodes. The~first one only registered an~empty callback. The~second one obtained the~symbol of the~inspected node from the~semantic model and then did a~dummy comparison of its name\footnote{This was just to make sure that the~compiler did not skip the~command of accessing the~semantic model, as part of an~optimization (if the~obtained symbol had not been used at all).}. Neither analyzer raised any diagnostic in the~CMS solution. 

The~difference between the~execution times of these analyzers was significant. While the~empty callback took 0.54 seconds on average \footnote{The~presented values are the~averages from 100 MSBuild runs of the~CMS solution, obtained from \textit{Report-Analyzer.ps1} script described in the~previous section. The~box plots can be seen in~Figure~\ref{fig:system-io-versions-boxplots}.}, the~second one run for an~average of 7.89 seconds. 

These measurement clearly showed, that if the~final version was to be faster, it had to implement some heuristic, that would allow to cut off the~analysis of inspected node without need to access the~semantic model. The~analysis logic of the~final solution is depicted by an~activity diagram in Figure~\ref{fig:uml-system-io-activity-diagram}. 

The~most important steps for the~optimization are the~second and the~third node of the~diagram (inspection of \textit{containing syntax tree} and \textit{containing dotted expression}\footnote{The~\textit{outermost dotted expression of an~identifier name} is the~outermost dotted expression of its parent, if the~parent is of kind \texttt{QualifiedName} or \texttt{SimpleMemberAccessExpression}, or the~node itself otherwise. For example, for identifier name \texttt{Stream} which is part of \texttt{System.IO.Stream} expression, the~outermost dotted expression is the~whole expression.}). They are performed purely on syntax and are extremely efficient in eliminating most of the~irrelevant nodes. 

To prevent multiple inspections of same syntax tree for all its identifier name nodes, the~information whether the~tree contains \texttt{System.IO} using is cached in a~concurrent dictionary. This optimization technique managed to shrink the~analyzer's execution time on the~CMS solution to an~average of 2.40~seconds, whereas the~non-cached version took 10.94~seconds on average. 

\begin{figure}
		\centering
			\includegraphics[scale=0.23]{img/system-io-versions-boxpolt}
		\caption{Box plots of execution times for different versions of~the~\texttt{SystemIOAnalyzer}. Each dataset contains one~hundred~measurements.}
		\label{fig:system-io-versions-boxplots}
\end{figure}

A box plot diagram in Figure~\ref{fig:system-io-versions-boxplots} depicts the~execution times of the~final analyzer (with non-cached version as well), \textit{V1} analyzer, and artificial analyzers serving as baselines. It is clear that the~cached version provides by far the~best results and was chosen as the~final implementation.

%\subsection{Other Optimizations}
%Apart from optimizations of \texttt{SystemIOAnalyzer}, other analyzers, that turned up slowest after the~initial implementation, were improved in terms of their execution times.
%
%\subsubsection{\textbf{CMS Base Classes Analyzers}}
%This optimization includes the~whole category of analyzers that inspect what base class the~classes derive from. The~earliest version of these analyzers registered syntax tree action and inspected all its class declarations. This approach turned out to be TODO slower than the~final one, in which a~symbol action for named types is registered. The~analyzers do not need to query the~semantic model, because the~information about the~inspected symbol is already present in the~symbol analysis context action parameter.
%
%Symbol actions get invoked exactly once per discovered named type. Since partial classes are declared on multiple locations, but they only have one symbol, the~diagnostic is raised for the~first location of all the~symbol's locations. 
%
%\subsubsection{\textbf{Syntax Heuristics for Method Invocation Analyzer}}
%Welp... this has not really helped.
%stats on how much it speeded up relevant analyzers
%
%\subsubsection{\textbf{String Analyzers}}
%As discussed in Section~\ref{sec:string-and-culture-approach-explained}, the~analyzers in \textit{String and Culture} category do not use the~\texttt{MethodInvocationAnalyzer} analysis helper as a~strategy. They use customized approach based on the~assumption, that all the~diagnosed invocation will be on strings. The~omission of the~\texttt{MethodInvocationAnalyzer} from these analyzers led to approximate TODO increase in analyzers speed.

\section{Impact on build times}
\label{sec:build-times}
After the~deployment of BugHunter analyzers to the~CMS solution, the~impact on the~overall build time had to be evaluated. In order to do that, the~durations CMS solution's MSBuilds prior and after the~analyzers' deployment were collected. Both versions of the~solution were built one hundred times and the~results of the~measurement are depicted in box plot diagram in Figure~\ref{fig:build-times-boxplots}.

\begin{figure}[h!]
		\centering   
			\includegraphics[scale=0.26]{img/build-time-boxplots}
		\caption{Box plots comparing the~MSBuild time of the~CMS solution with and without BugHunter analyzers. Each dataset contains one~hundred~measurements.}
		\label{fig:build-times-boxplots}
\end{figure}

The~version without the~analyzers took an~average of 5.09~minutes to build, whereas for the~version with installed BugHunter analyzers it was 5.24~minutes. This means an~average of 9~seconds that were added to the~total build time. Considering this represents only 2.9\%, it is  not a~significant slowdown.

\newpage
\section{Tool Evaluation}
One week after the~deployment of BugHunter analyzers, a~questionnaire was sent to the~development team at Kentico. The~full version, along with the~results, can be found in Appendix~\ref{appendix:questionnaire}. 

The~primary goal was to evaluate these categories:

\begin{itemize}
\item[\textbf{Performance:}] Had they been experiencing any performance issues after the~BugHunter analyzers' deployment? If so, what IDE set-up were the~developers using?

\item[\textbf{Correctness:}] Had they encountered any false positives/negatives while using the~tool?

\item[\textbf{Code fixes:}] Had they already used any suggested code fix? Did they it useful?
\end{itemize}

Out of approximately 19~developers currently working on the~product, 10~participated in the~survey. None of them complained about any performance degradation. The~interesting fact to find out was that 60\% of them did not use any third party tools for static code analysis, while the~rest mostly used ReSharper.

When asked about the~false positive or false negative results from the~tool, more than three quarters responded that they had not encountered any, while the~others answered \textit{"Not sure"}.

One half of the~respondents had already been suggested a~code fix and they had found it useful. Ninety percent of them also applied the~suggested code fix and 7 out of 10 participants had believed the~code fixes would help the~new developers to learn the~internal CMS guidelines more quickly.

% TOOD mention "testing" of performance in VS.. codefixes?

% =================================================================
% ============================= CHAPTER 7 =========================
% =================================================================
\chapter{Conclusion}
The~goal of this thesis was to create a~custom static code analysis tool for Kentico company, using the~new .NET Compiler Platform (\textit{"Roslyn"}). The~tool was developed to replace an~existing console application that scanned the~Kentico source codes, and searched for violations of company's internal rules and coding guidelines.

The~theoretical part of the~thesis explained the~theory behind compiling the~source code which was crucial for the~following chapters about static code analysis. It listed static code analysis tools available for .NET and then presented the~new .NET Compiler Platform and how it could be used for building custom  analyzers. The~second part of this thesis described the~implementation of the~new BugHunter analyzers and discussed the~added value for the~company, as well as the~need for measuring and optimizing their performance.

The~objectives of the~thesis were met and the~developed tool has already been installed to Kentico's CMS solution. It represents a~significant upgrade to the~previous simple console application, in terms of correctness, user experience and presence of code fixes suggested for the~diagnosed issues. The~questionnaire sent to the~development team, one week after the~analyzers' deployment, did not reveal any issues concerning tool's stability nor performance.

Rewriting the~internal rules to Roslyn enabled more involved semantic analysis of the~source code and paved the~way for advanced checks that were problematic in the~previous solution. This not only led to discovering quite a~few previously undetected issues in the~code base, but it also enabled elimination of some obscure pieces of code, that were only present to avoid false positive results from the~original BugHunter application. 

The~extensive suite of unit tests, that was written for the~new analyzers, makes it possible to track the~API changes of the~Kentico's solution, and keep the~analysis rules up to date with the~analyzed source code. Moreover, they also helped to uncover number of bugs present in the~original BugHunter.

The~new analyzers run as part of the~continuous integration process, enforcing the~compliance to the~internal rules across the~whole company. The~fact that they are also integrated to the~Visual Studio minimizes the~time the~developer needs to wait for the~first feedback on his code. Majority of the~analyzers also provide a~code fix for the~issue which may help the~new developers on the~team to learn the~practices followed in the~company more quickly.

Many helpers methods and strategy classes for analysis were created, which makes the~rule set easily extendible, even for someone without a~previous experience with Roslyn. The~current version of the~Roslyn API used by the~analyzers is~1.3.2. During the~course of writing this thesis, version~2.0 was released and it provides some new features and promises a~better performance. However, since the~most of developers at Kentico are still using Visual Studio 2015, the~version of Roslyn was not updated because it requires Visual Studio 2017. Once the~whole development team migrates to the~new version of the~IDE, the~version of the~.NET Compiler Platform should be updated as well.

Although the~tool was primarily developed to aid the~Kentico employees and enforce the~guidelines within the~company, in the~future, it could be also used by the~customers who work with the~Kentico API or have purchased the~licence that includes the~Kentico source codes. The~NuGet packages with BugHunter analyzers are currently only available at Kentico internal NuGet feed. However, after the~tool is adopted company wide, the~plan is to make it publicly available through the~NuGet Gallery. Afterwards, anyone interested would be able to leverage the~static code analysis guiding them to intended use of the~Kentico API in their own projects.


%Why stateful analyzers should not have compilation end actions -- for large solutions it can take more than one minute for the~diagnostic to show up in VS... that is not usable at all and cannot be considered as "live" feedback.

%
%\section{Roslyn as SDK and Its Usage -- Considerations and Remarks}
%Changing versions ... not really well documented
%Only issues on GH provide some insight
%e.g. SkipGeneratedCoOdeAnalysis or RunAnalyzersInParallel - some discussions on GitHub but not clear outcomes, sometimes proposition does not math the~actual implementation and it is generally hard to find some best practices on how to do stuff ad it is still a~pretty young tech... moreover the~examples are not really updated according to new versions of the~API so one struggles with implemeting something on his own only to find a~few weeks later that it was added or it is considered for the~next milestone
%
%many useful things are marked as internal in the~source code and there are many issues on GH to make them public
%
%current version used is v.1.3.X and for this on VS with Update 3 is needed... had to be installed on all build boxes to accomodete BH depoloyment
%
%... version v2 was released after the~implemetnation was finished and it was considered although it was agreed we will not use it as it required VS2017 and nobody is happy about it.. talk about some cons...
%
%(  - ConfigureGeneratedCodeAnalysis - big boost when roslyn API allowed to opt out for analyzer to be run on generated code. Before, heuristics had to be performed by analyzers themselves on every callback
%   https://github.com/dotnet/roslyn/issues/6998
%   https://github.com/dotnet/roslyn/pull/7526)
%
%- problem with Symbol location and disappearing diagnostic 

% =================================================================
% =============================== STUFF ===========================
% =================================================================
% From template
%\makeatletter\thesis@blocks@clear\makeatother
%\phantomsection %% Print the~index and insert it into the
%\addcontentsline{toc}{chapter}{\indexname} %% table of contents.

%\printindex
    
% =================================================================
% =========================== BIBLIOGRAPHY ========================
% =================================================================
\printbibliography
% =================================================================
% ============================ APPENDIX A =========================
% =================================================================    
\appendix %% Start the~appendices.
\chapter{Source Codes in IS}
\label{appendix:source-codes}
TODO...

The~main solution with new Roslyn analyzers (BugHunter.sln) consists of 6 projects within 2 folders: 

TODO - Do leave the~Vsix project there or delete???

\begin{description}
  \item[Analyzers folder] with Roslyn analyzers
  \begin{itemize}
    \item BugHunter.Core
    \item BugHunter.Analyzers
    \item BugHunter.Web.Analyzers
  \end{itemize}
  
  \item[Tests folder] with tests:
  \begin{itemize}
    \item BugHunter.TestUtils
    \item BugHunter.Core.Test
    \item BugHunter.Analyzers.Test
    \item BugHunter.Web.Analyzers.Test
  \end{itemize}
\end{description}

TODO Describe each project.. why 2 for analyzers - nuget distribution

The~projects with analyzers use the~categories also for folder structure with each folder containing separate subfolders for analyzers and code fixes respectively.

% =================================================================
% ============================= APPENDIX B =========================
% =================================================================
\chapter{Questionnaire}
\label{appendix:questionnaire}
This appendix contains the~original version of the~questionnaire sent to the~development team one week after the~deployment along with the~results:

\bigskip\noindent
\textit{Hi, all!}

\bigskip\noindent
\textit{On 24.4.2017 new NuGet package with BugHunter Roslyn analyzers was installed to CMS Solution. It aims to replace the~C\# checks of the~original BugHunter (a console application that runs on build boxes) and provide a~better developer experience with instant feedback inside of Visual Studio.}

\textit{The~new analyzers were implemented as a~part of diploma thesis on FI MUNI. The~goal of this survey is to collect feedback from developers that are already using the~tool on daily basis, in order to assess whether the~goals of the~thesis were met.}

\textit{There are only 8 required multiple choice questions, and it should not take you more than 3 minutes to fill in.}

\bigskip\noindent
\textit{Thanks in advance for your participation,}
\\ \noindent
\textit{Zuzana Dankovcikova}

\begin{center}
\textbf{Your environment}
\end{center}

\smallskip\noindent
\textbf{What version of Visual Studio do you use?}
\begin{compactitem}
\item VS2017 \textit{30\%}
\item VS2015 Update 3 \textit{70\%}
\item Older \textit{0\%}
\end{compactitem}

\smallskip\noindent
\textbf{What tools for static code analysis do you use?\footnote{Multiple answeres possible, the~results do not have to sum up to 100\%.}}
\begin{compactitem}
\item None \textit{70\%}
\item ReSharper \textit{40\%}
\item StyleCop \textit{0\%}
\item FxCop \textit{0\%}
\item CodeRush \textit{0\%}
\item CodeCracker \textit{10\%}
\item Other \textit{0\%}
\end{compactitem}

\begin{center}
\textbf{Code Fixes}
\end{center}

\smallskip\noindent
\textbf{Have you already used any code fix suggested by BugHunter?}
\begin{compactitem}
\item Yes \textit{40\%}
\item No \textit{60\%}
\end{compactitem}

\smallskip\noindent
\textbf{Do you find the~new code fixes useful?}
\begin{compactitem}
\item Yes \textit{50\%}
\item No \textit{0\%}
\item Have not encountered any \textit{50\%}
\end{compactitem}

\smallskip\noindent
\textbf{Do you think the~BugHunter analyzers and code fixes will help new developers to learn the~internal CMS guidelines more quickly?}
\begin{compactitem}
\item Yes \textit{70\%}
\item No \textit{10\%}
\item Not sure \textit{20\%}
\end{compactitem}

\begin{center}
\textbf{Performance}
\end{center}

\smallskip\noindent
\textbf{Have you been experiencing unusual performance issues with your Visual Studio since the~analyzers' deployment (Monday 24.4.2017)?}
\begin{compactitem}
\item Yes \textit{90\%}
\item No \textit{0\%}
\item Not sure \textit{10\%}
\end{compactitem}

\begin{center}
\textbf{Correctness}
\end{center}

In the~context of static code analysis:
- a~"false positive" is an~issue that was incorrectly reported by the~tool,
- a~"false negative" is an~issue that is present in the~code but was not detected by the~tool.

\smallskip\noindent
\textbf{Have you encountered any false positive results?}
\begin{compactitem}
\item Yes \textit{0\%}
\item No \textit{90\%}
\item Not sure \textit{10\%}
\end{compactitem}

\smallskip\noindent
\textbf{Have you encountered any false negatives?}
\begin{compactitem}
\item Yes \textit{0\%}
\item No \textit{80\%}
\item Not sure \textit{20\%}
\end{compactitem}

\begin{center}
\textbf{Additional information}
\end{center}

\smallskip\noindent
\textbf{Do you have any other comments/suggestions?}

-

% =================================================================
% ============================= APPENDIX C =========================
% =================================================================
\chapter{Deployment, Configuration and Versioning}
\label{appendix:deployment}
The aim of this appendix is to explain the details about the installation and the initial configuration that had to be set up in order for the new analyzers to mimic the configuration of the original BugHunter checks. It also shortly mentions how the NuGet updates are to be performed. An online documentation for all developed analyzers, created as part of the thesis, can be found~\cite{online-documentation} TODO.

On 24.4.2017 the developed BugHunter analyzers were installed to the \textit{CMS} solution in form of two NuGet packages. This means that everybody working with the solution locally, as well as the build machines on TeamCity (continuous integration server), are already using it. This process required upgrade of the Visual Studio on the TeamCity servers, since the analyzers need VS2015 with Update 3 to work. 

\section{Two NuGet packages with BugHunter Analyzers}
In the original BugHunter, some of the checks were only performed in \textit{CMSApp} project -- a project with the web application that is shipped to the customers. Although it was possible to disable the corresponding analyzers for all other projects in the \textit{CMS} solution, more suitable option seemed to be separating those analyzers into a standalone NuGet package that would be installed to the \textit{CMSApp} project only. This way, the configuration is not bloated with unnecessary settings.

The main NuGet package is called \textit{BugHunter.Analyzers} and it contains total of 24 analyzers (for more information on which those analyzers are, see the online documentation~\cite{online-documentation}. It is installed to 125 projects of the \textit{CMS} solution. Projects containing tests, as well as some some projects containing the third-party libraries, were excluded from the installation.

The second NuGet package, installed solely to the \textit{CMSApp} project, is called \textit{BugHunter.Web.Analyzers} and contains 5~analyzers.

The current version for both NuGet packages installed is \textit{1.0.0}. This version is compatible with Kentico version 10.0.13. The idea is for the versioning to follow the rules of the semantic versioning\footnote{\url{http://semver.org}}.

An important thing to mention is that the packages are not yet available via the official Microsoft NuGet Gallery and are downloaded from Kentico's internal NuGet feed.

\section{Applying the configuration of original BugHunter}
The above mentioned separation into two NuGet packages was only the first step of applying the old configuration. The old BugHunter contained a long \textit{app.config} file, containing excluded paths per check (for whole folders or separate files). These settings had to be reflected in order to get rid of over 500 warnings produced by new analyzers right after the installation.

\subsubsection{\textbf{Disabling Analyzers for Projects -- Rule Set File}}
The \textit{.ruleset} files\footnote{\url{https://github.com/dotnet/roslyn/blob/master/docs/compilers/Rule\%20Set\%20Format.md}} are a convenient way to turn the analyzers on and off and configure their severity per project. All implemented analyzer are enabled by default and severity is set to warning in their diagnostic descriptors. However, since some analyzers, mainly \texttt{SystemIOAnalyzer}, are not meant to analyze every project, but it would be pointless to create NuGet with only one analyzer, the Rule Sets were used. 

The SystemIOAnalyzer has the rule action set to \texttt{None} in some of the projects which means they are effectively turned off in those projects. Those projects include \textit{CMS.IO} project, that is basically a \textit{CMS} wrapper of \textit{System.IO} namespace, and also projects that provide I/O operations for other file systems like Azure or Amazon storage. List of all the excluded projects can be found in the online documentation.

\subsubsection{\textbf{Disabling Analyzers in Code -- Pragma Warnings}}
One of the advantages of Roslyn, compared to the old BugHunter, is that the disabling of the analyzers is more granular and the configuration is placed directly in the code. There are two options for suppressing the analyzers' warnings for a piece of code:
\begin{itemize}
  \item \textbf{pragma warning}\footnote{\url{https://docs.microsoft.com/en-us/dotnet/articles/csharp/language-reference/preprocessor-directives/preprocessor-pragma-warning}} -- preprocessor directive for temporary disabling and later enabling the analysis for any line(s) of code,
  \item \textbf{supress message}\footnote{\url{https://msdn.microsoft.com/en-us/library/ms244717.aspx}} -- attribute for disabling an analyzer over specified unit (member, type, namespace, or module).
\end{itemize}

Since in context of \textit{CMS} solution, sometimes supressing the analysis over single line of code is necessary and mixing the two approaches was undesirable, pragma warnings were applied.

For helper classes serving as CMS replacements for traditional Microsoft API, the concrete \textit{CMS API Replacement} analyzer was disabled for the whole file using explicit pragma warning statements around the class code. For example, whole class \texttt{BrowserHelper} (which should be always used instead of directly accessing the \texttt{Browser} property of \texttt{HttpRequest} object) has the \texttt{HttpRequestBrowserAnalyzer} (id \textit{BH1007} disabled like this:

\begin{minted}{csharp}
// Enable use of 'Request.Browser' for this file
#pragma warning disable BH1007 
public static class BrowserHelper
{
    // methods
}
#pragma warning restore BH1007
\end{minted}

Pragma warnings were also applied in some rare cases, where the issue reported by the analyzer could have been fixed.

\subsubsection{\textbf{Fixing outstanding issues}}
After applying the old configuration, there were still over one hundred warnings reported by the BugHunter analyzers. These were all false negative results that had not been previously detected by the original BugHunter. 

The most common were errors from \textit{String and Culture} category, where the semantic analysis uncovered quite a few usages of \texttt{Equals()} or \texttt{IndexOf} methods without specifying string comparison or culture info argument. All of those had to be manually fixed and the automated code fixes made the job a lot easier.

Another large group of warnings was from previously most problematic check -- \texttt{System.IO}. The new analyzer exposed many forbidden usages of \texttt{System.IO} members that were missed by the old tool. In most of the  cases, the warnings were fixed, sometimes pragma warnings were used to diable the analyzer with an appropriate message.

\end{document}
